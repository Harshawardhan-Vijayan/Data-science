{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"fordTrain.csv\")\n",
    "test  = pd.read_csv(\"fordTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialID</th>\n",
       "      <th>ObsNum</th>\n",
       "      <th>IsAlert</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>E3</th>\n",
       "      <th>E4</th>\n",
       "      <th>E5</th>\n",
       "      <th>E6</th>\n",
       "      <th>E7</th>\n",
       "      <th>E8</th>\n",
       "      <th>E9</th>\n",
       "      <th>E10</th>\n",
       "      <th>E11</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.0</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.0</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.0</td>\n",
       "      <td>604329.000000</td>\n",
       "      <td>604329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.167657</td>\n",
       "      <td>603.841765</td>\n",
       "      <td>0.578799</td>\n",
       "      <td>35.449020</td>\n",
       "      <td>11.996525</td>\n",
       "      <td>1026.671035</td>\n",
       "      <td>64.061965</td>\n",
       "      <td>0.178923</td>\n",
       "      <td>845.384610</td>\n",
       "      <td>77.887628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.512332</td>\n",
       "      <td>102.790045</td>\n",
       "      <td>0.290565</td>\n",
       "      <td>-4.230136</td>\n",
       "      <td>0.016262</td>\n",
       "      <td>358.674738</td>\n",
       "      <td>1.757296</td>\n",
       "      <td>1.383058</td>\n",
       "      <td>0.876787</td>\n",
       "      <td>63.311256</td>\n",
       "      <td>1.315265</td>\n",
       "      <td>76.965412</td>\n",
       "      <td>-0.037710</td>\n",
       "      <td>573.786433</td>\n",
       "      <td>19.961030</td>\n",
       "      <td>0.179814</td>\n",
       "      <td>1715.688383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.710354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.312257</td>\n",
       "      <td>11.668277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>145.446164</td>\n",
       "      <td>348.931601</td>\n",
       "      <td>0.493752</td>\n",
       "      <td>7.484629</td>\n",
       "      <td>3.760292</td>\n",
       "      <td>309.277877</td>\n",
       "      <td>19.755950</td>\n",
       "      <td>0.372309</td>\n",
       "      <td>2505.335141</td>\n",
       "      <td>18.577930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.049071</td>\n",
       "      <td>127.258629</td>\n",
       "      <td>1.006162</td>\n",
       "      <td>35.508596</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>27.399973</td>\n",
       "      <td>2.854852</td>\n",
       "      <td>1.608807</td>\n",
       "      <td>0.328681</td>\n",
       "      <td>18.891029</td>\n",
       "      <td>5.247204</td>\n",
       "      <td>44.387031</td>\n",
       "      <td>0.403896</td>\n",
       "      <td>298.412888</td>\n",
       "      <td>63.269456</td>\n",
       "      <td>0.384033</td>\n",
       "      <td>618.176470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.532085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.243586</td>\n",
       "      <td>9.934423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-22.481200</td>\n",
       "      <td>-45.629200</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>23.885300</td>\n",
       "      <td>0.038920</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.262224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-250.000000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.795000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.676730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.758100</td>\n",
       "      <td>9.903540</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>49.180300</td>\n",
       "      <td>0.092110</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>66.666700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.930000</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.487500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1259.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.947680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.145100</td>\n",
       "      <td>11.400400</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.105083</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>3.018750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.772600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>374.000000</td>\n",
       "      <td>906.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.311900</td>\n",
       "      <td>13.644200</td>\n",
       "      <td>1220.000000</td>\n",
       "      <td>75.757600</td>\n",
       "      <td>0.138814</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>89.820400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.240000</td>\n",
       "      <td>211.584000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.016694</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>7.481250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2146.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.270900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>510.000000</td>\n",
       "      <td>1210.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>101.351000</td>\n",
       "      <td>71.173700</td>\n",
       "      <td>2512.000000</td>\n",
       "      <td>119.048000</td>\n",
       "      <td>27.202200</td>\n",
       "      <td>228812.000000</td>\n",
       "      <td>468.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.991000</td>\n",
       "      <td>359.995000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.023939</td>\n",
       "      <td>513.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>52.400000</td>\n",
       "      <td>129.700000</td>\n",
       "      <td>3.990000</td>\n",
       "      <td>1023.000000</td>\n",
       "      <td>484.488000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4892.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>262.534000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TrialID         ObsNum        IsAlert             P1  \\\n",
       "count  604329.000000  604329.000000  604329.000000  604329.000000   \n",
       "mean      250.167657     603.841765       0.578799      35.449020   \n",
       "std       145.446164     348.931601       0.493752       7.484629   \n",
       "min         0.000000       0.000000       0.000000     -22.481200   \n",
       "25%       125.000000     302.000000       0.000000      31.758100   \n",
       "50%       250.000000     604.000000       1.000000      34.145100   \n",
       "75%       374.000000     906.000000       1.000000      37.311900   \n",
       "max       510.000000    1210.000000       1.000000     101.351000   \n",
       "\n",
       "                  P2             P3             P4             P5  \\\n",
       "count  604329.000000  604329.000000  604329.000000  604329.000000   \n",
       "mean       11.996525    1026.671035      64.061965       0.178923   \n",
       "std         3.760292     309.277877      19.755950       0.372309   \n",
       "min       -45.629200     504.000000      23.885300       0.038920   \n",
       "25%         9.903540     792.000000      49.180300       0.092110   \n",
       "50%        11.400400    1000.000000      60.000000       0.105083   \n",
       "75%        13.644200    1220.000000      75.757600       0.138814   \n",
       "max        71.173700    2512.000000     119.048000      27.202200   \n",
       "\n",
       "                  P6             P7        P8             E1             E2  \\\n",
       "count  604329.000000  604329.000000  604329.0  604329.000000  604329.000000   \n",
       "mean      845.384610      77.887628       0.0      10.512332     102.790045   \n",
       "std      2505.335141      18.577930       0.0      14.049071     127.258629   \n",
       "min       128.000000       0.262224       0.0       0.000000       0.000000   \n",
       "25%       668.000000      66.666700       0.0       0.000000       0.000000   \n",
       "50%       800.000000      75.000000       0.0       0.000000       0.000000   \n",
       "75%       900.000000      89.820400       0.0      28.240000     211.584000   \n",
       "max    228812.000000     468.750000       0.0     243.991000     359.995000   \n",
       "\n",
       "                  E3             E4             E5             E6  \\\n",
       "count  604329.000000  604329.000000  604329.000000  604329.000000   \n",
       "mean        0.290565      -4.230136       0.016262     358.674738   \n",
       "std         1.006162      35.508596       0.002304      27.399973   \n",
       "min         0.000000    -250.000000       0.008000     260.000000   \n",
       "25%         0.000000      -8.000000       0.015686     348.000000   \n",
       "50%         0.000000       0.000000       0.016001     365.000000   \n",
       "75%         0.000000       6.000000       0.016694     367.000000   \n",
       "max         4.000000     260.000000       0.023939     513.000000   \n",
       "\n",
       "                  E7             E8             E9            E10  \\\n",
       "count  604329.000000  604329.000000  604329.000000  604329.000000   \n",
       "mean        1.757296       1.383058       0.876787      63.311256   \n",
       "std         2.854852       1.608807       0.328681      18.891029   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000      52.000000   \n",
       "50%         1.000000       1.000000       1.000000      67.000000   \n",
       "75%         2.000000       2.000000       1.000000      73.000000   \n",
       "max        25.000000       9.000000       1.000000     127.000000   \n",
       "\n",
       "                 E11             V1             V2             V3  \\\n",
       "count  604329.000000  604329.000000  604329.000000  604329.000000   \n",
       "mean        1.315265      76.965412      -0.037710     573.786433   \n",
       "std         5.247204      44.387031       0.403896     298.412888   \n",
       "min         0.000000       0.000000      -4.795000     240.000000   \n",
       "25%         0.000000      41.930000      -0.175000     255.000000   \n",
       "50%         0.000000     100.400000       0.000000     511.000000   \n",
       "75%         0.000000     108.500000       0.070000     767.000000   \n",
       "max        52.400000     129.700000       3.990000    1023.000000   \n",
       "\n",
       "                  V4             V5             V6        V7             V8  \\\n",
       "count  604329.000000  604329.000000  604329.000000  604329.0  604329.000000   \n",
       "mean       19.961030       0.179814    1715.688383       0.0      12.710354   \n",
       "std        63.269456       0.384033     618.176470       0.0      11.532085   \n",
       "min         0.000000       0.000000       0.000000       0.0       0.000000   \n",
       "25%         1.487500       0.000000    1259.000000       0.0       0.000000   \n",
       "50%         3.018750       0.000000    1994.000000       0.0      12.800000   \n",
       "75%         7.481250       0.000000    2146.000000       0.0      21.900000   \n",
       "max       484.488000       1.000000    4892.000000       0.0      82.100000   \n",
       "\n",
       "             V9            V10            V11  \n",
       "count  604329.0  604329.000000  604329.000000  \n",
       "mean        0.0       3.312257      11.668277  \n",
       "std         0.0       1.243586       9.934423  \n",
       "min         0.0       1.000000       1.676730  \n",
       "25%         0.0       3.000000       7.947680  \n",
       "50%         0.0       4.000000      10.772600  \n",
       "75%         0.0       4.000000      15.270900  \n",
       "max         0.0       7.000000     262.534000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train.dtypes\n",
    "x = train.describe()\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x250b23b49b0>,\n",
       "  <matplotlib.lines.Line2D at 0x250b23b4cf8>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x250b23b4dd8>,\n",
       "  <matplotlib.lines.Line2D at 0x250b23d33c8>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x250b23b4588>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x250b23d3710>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x250b23d3a58>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.boxplot(train['P5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialID</th>\n",
       "      <th>ObsNum</th>\n",
       "      <th>IsAlert</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>E3</th>\n",
       "      <th>E4</th>\n",
       "      <th>E5</th>\n",
       "      <th>E6</th>\n",
       "      <th>E7</th>\n",
       "      <th>E8</th>\n",
       "      <th>E9</th>\n",
       "      <th>E10</th>\n",
       "      <th>E11</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V8</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TrialID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.145816</td>\n",
       "      <td>0.016772</td>\n",
       "      <td>-0.004473</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.022632</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.111903</td>\n",
       "      <td>-0.061881</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>-0.087071</td>\n",
       "      <td>-0.050151</td>\n",
       "      <td>0.234524</td>\n",
       "      <td>-0.034418</td>\n",
       "      <td>-0.116919</td>\n",
       "      <td>-0.095434</td>\n",
       "      <td>0.116988</td>\n",
       "      <td>-0.100521</td>\n",
       "      <td>0.073676</td>\n",
       "      <td>-0.117728</td>\n",
       "      <td>0.065063</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.074320</td>\n",
       "      <td>0.123721</td>\n",
       "      <td>-0.097389</td>\n",
       "      <td>-0.047593</td>\n",
       "      <td>-0.093818</td>\n",
       "      <td>0.078887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ObsNum</th>\n",
       "      <td>-0.000162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005143</td>\n",
       "      <td>0.018324</td>\n",
       "      <td>-0.001764</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>-0.001191</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>-0.015791</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>-0.004580</td>\n",
       "      <td>0.010314</td>\n",
       "      <td>-0.003838</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>-0.002779</td>\n",
       "      <td>-0.008684</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>-0.000480</td>\n",
       "      <td>-0.006284</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>-0.011465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsAlert</th>\n",
       "      <td>-0.145816</td>\n",
       "      <td>-0.005143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>-0.008177</td>\n",
       "      <td>0.038160</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>0.189796</td>\n",
       "      <td>-0.160830</td>\n",
       "      <td>-0.105495</td>\n",
       "      <td>0.157973</td>\n",
       "      <td>0.047992</td>\n",
       "      <td>-0.067453</td>\n",
       "      <td>-0.189198</td>\n",
       "      <td>-0.329722</td>\n",
       "      <td>-0.283440</td>\n",
       "      <td>0.380353</td>\n",
       "      <td>-0.067051</td>\n",
       "      <td>0.079002</td>\n",
       "      <td>-0.269967</td>\n",
       "      <td>-0.050740</td>\n",
       "      <td>-0.062000</td>\n",
       "      <td>0.097022</td>\n",
       "      <td>0.055429</td>\n",
       "      <td>-0.244150</td>\n",
       "      <td>-0.165550</td>\n",
       "      <td>-0.259607</td>\n",
       "      <td>0.155722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1</th>\n",
       "      <td>0.016772</td>\n",
       "      <td>0.018324</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006674</td>\n",
       "      <td>-0.010317</td>\n",
       "      <td>0.011704</td>\n",
       "      <td>0.010911</td>\n",
       "      <td>0.045429</td>\n",
       "      <td>0.027461</td>\n",
       "      <td>-0.015436</td>\n",
       "      <td>-0.009356</td>\n",
       "      <td>0.024131</td>\n",
       "      <td>-0.010574</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>-0.004635</td>\n",
       "      <td>-0.013194</td>\n",
       "      <td>-0.010918</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.004549</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>-0.025763</td>\n",
       "      <td>-0.021118</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.021404</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>-0.019792</td>\n",
       "      <td>-0.029747</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>0.344636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P2</th>\n",
       "      <td>-0.004473</td>\n",
       "      <td>-0.001764</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>-0.006674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002539</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>-0.022003</td>\n",
       "      <td>0.052171</td>\n",
       "      <td>-0.012045</td>\n",
       "      <td>-0.019121</td>\n",
       "      <td>0.062076</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>-0.005140</td>\n",
       "      <td>-0.006843</td>\n",
       "      <td>-0.002058</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.014589</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.011310</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>-0.006038</td>\n",
       "      <td>-0.023902</td>\n",
       "      <td>0.010608</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>-0.034248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P3</th>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>-0.010317</td>\n",
       "      <td>-0.002539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.944435</td>\n",
       "      <td>0.035129</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>-0.006097</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>-0.016437</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>-0.004508</td>\n",
       "      <td>-0.014086</td>\n",
       "      <td>-0.014135</td>\n",
       "      <td>0.018113</td>\n",
       "      <td>-0.013289</td>\n",
       "      <td>0.007423</td>\n",
       "      <td>-0.011347</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>-0.006380</td>\n",
       "      <td>0.013045</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>-0.010245</td>\n",
       "      <td>-0.007963</td>\n",
       "      <td>-0.009630</td>\n",
       "      <td>-0.009808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P4</th>\n",
       "      <td>0.001880</td>\n",
       "      <td>-0.001191</td>\n",
       "      <td>-0.008177</td>\n",
       "      <td>0.011704</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>-0.944435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032897</td>\n",
       "      <td>-0.010627</td>\n",
       "      <td>0.007323</td>\n",
       "      <td>-0.004870</td>\n",
       "      <td>-0.010749</td>\n",
       "      <td>0.010696</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0.012959</td>\n",
       "      <td>-0.016615</td>\n",
       "      <td>0.010501</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>-0.006926</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>-0.010905</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.009841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P5</th>\n",
       "      <td>0.022632</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>0.038160</td>\n",
       "      <td>0.010911</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>0.035129</td>\n",
       "      <td>-0.032897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>-0.023628</td>\n",
       "      <td>-0.062955</td>\n",
       "      <td>-0.033420</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>-0.002757</td>\n",
       "      <td>-0.020218</td>\n",
       "      <td>-0.006387</td>\n",
       "      <td>-0.032576</td>\n",
       "      <td>-0.048551</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>-0.074753</td>\n",
       "      <td>0.028216</td>\n",
       "      <td>-0.054428</td>\n",
       "      <td>0.026232</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.070290</td>\n",
       "      <td>-0.016671</td>\n",
       "      <td>-0.046353</td>\n",
       "      <td>-0.023359</td>\n",
       "      <td>-0.022193</td>\n",
       "      <td>-0.004897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P6</th>\n",
       "      <td>0.005377</td>\n",
       "      <td>-0.015791</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>0.045429</td>\n",
       "      <td>-0.022003</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>-0.010627</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.125580</td>\n",
       "      <td>-0.006273</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>-0.025157</td>\n",
       "      <td>-0.001288</td>\n",
       "      <td>-0.007514</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>-0.006923</td>\n",
       "      <td>-0.008941</td>\n",
       "      <td>-0.005549</td>\n",
       "      <td>-0.034470</td>\n",
       "      <td>-0.008939</td>\n",
       "      <td>-0.024449</td>\n",
       "      <td>-0.010418</td>\n",
       "      <td>-0.004996</td>\n",
       "      <td>0.019121</td>\n",
       "      <td>0.029222</td>\n",
       "      <td>-0.025728</td>\n",
       "      <td>-0.016850</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>0.012783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P7</th>\n",
       "      <td>0.111903</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.189796</td>\n",
       "      <td>0.027461</td>\n",
       "      <td>0.052171</td>\n",
       "      <td>-0.006097</td>\n",
       "      <td>0.007323</td>\n",
       "      <td>-0.023628</td>\n",
       "      <td>-0.125580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087373</td>\n",
       "      <td>-0.091327</td>\n",
       "      <td>0.294528</td>\n",
       "      <td>0.026627</td>\n",
       "      <td>0.051338</td>\n",
       "      <td>-0.105148</td>\n",
       "      <td>-0.042634</td>\n",
       "      <td>0.022973</td>\n",
       "      <td>0.045725</td>\n",
       "      <td>0.109924</td>\n",
       "      <td>0.084846</td>\n",
       "      <td>-0.043512</td>\n",
       "      <td>0.025850</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>0.037711</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>-0.020696</td>\n",
       "      <td>-0.008450</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>0.019360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E1</th>\n",
       "      <td>-0.061881</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.160830</td>\n",
       "      <td>-0.015436</td>\n",
       "      <td>-0.012045</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>-0.004870</td>\n",
       "      <td>-0.062955</td>\n",
       "      <td>-0.006273</td>\n",
       "      <td>-0.087373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.725684</td>\n",
       "      <td>-0.210994</td>\n",
       "      <td>-0.001312</td>\n",
       "      <td>0.046620</td>\n",
       "      <td>0.011380</td>\n",
       "      <td>0.114083</td>\n",
       "      <td>0.092611</td>\n",
       "      <td>-0.066801</td>\n",
       "      <td>0.176868</td>\n",
       "      <td>-0.088023</td>\n",
       "      <td>0.430603</td>\n",
       "      <td>0.068999</td>\n",
       "      <td>0.045605</td>\n",
       "      <td>-0.185484</td>\n",
       "      <td>-0.114477</td>\n",
       "      <td>0.399214</td>\n",
       "      <td>0.227876</td>\n",
       "      <td>0.382013</td>\n",
       "      <td>-0.070397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2</th>\n",
       "      <td>0.015610</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.105495</td>\n",
       "      <td>-0.009356</td>\n",
       "      <td>-0.019121</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>-0.010749</td>\n",
       "      <td>-0.033420</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>-0.091327</td>\n",
       "      <td>0.725684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.230564</td>\n",
       "      <td>-0.003982</td>\n",
       "      <td>0.041188</td>\n",
       "      <td>0.044847</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>-0.003062</td>\n",
       "      <td>-0.001179</td>\n",
       "      <td>-0.052130</td>\n",
       "      <td>0.094731</td>\n",
       "      <td>0.029370</td>\n",
       "      <td>-0.003652</td>\n",
       "      <td>-0.060586</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.044731</td>\n",
       "      <td>0.081133</td>\n",
       "      <td>-0.061395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E3</th>\n",
       "      <td>-0.087071</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.157973</td>\n",
       "      <td>0.024131</td>\n",
       "      <td>0.062076</td>\n",
       "      <td>-0.016437</td>\n",
       "      <td>0.010696</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>-0.025157</td>\n",
       "      <td>0.294528</td>\n",
       "      <td>-0.210994</td>\n",
       "      <td>-0.230564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016046</td>\n",
       "      <td>-0.121065</td>\n",
       "      <td>-0.165577</td>\n",
       "      <td>-0.075357</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.016521</td>\n",
       "      <td>0.035559</td>\n",
       "      <td>0.011117</td>\n",
       "      <td>0.015578</td>\n",
       "      <td>-0.046786</td>\n",
       "      <td>0.048736</td>\n",
       "      <td>0.140578</td>\n",
       "      <td>-0.079563</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>0.042666</td>\n",
       "      <td>0.115566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E4</th>\n",
       "      <td>-0.050151</td>\n",
       "      <td>-0.004580</td>\n",
       "      <td>0.047992</td>\n",
       "      <td>-0.010574</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>-0.002757</td>\n",
       "      <td>-0.001288</td>\n",
       "      <td>0.026627</td>\n",
       "      <td>-0.001312</td>\n",
       "      <td>-0.003982</td>\n",
       "      <td>0.016046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118974</td>\n",
       "      <td>0.060057</td>\n",
       "      <td>-0.202970</td>\n",
       "      <td>-0.119815</td>\n",
       "      <td>0.156194</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>-0.015727</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>-0.002248</td>\n",
       "      <td>-0.007556</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>-0.006332</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>-0.014779</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>-0.003311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E5</th>\n",
       "      <td>0.234524</td>\n",
       "      <td>0.010314</td>\n",
       "      <td>-0.067453</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>-0.005140</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>-0.020218</td>\n",
       "      <td>-0.007514</td>\n",
       "      <td>0.051338</td>\n",
       "      <td>0.046620</td>\n",
       "      <td>0.041188</td>\n",
       "      <td>-0.121065</td>\n",
       "      <td>0.118974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014476</td>\n",
       "      <td>-0.035202</td>\n",
       "      <td>0.021078</td>\n",
       "      <td>0.057401</td>\n",
       "      <td>0.037778</td>\n",
       "      <td>0.039560</td>\n",
       "      <td>0.079413</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>-0.016252</td>\n",
       "      <td>-0.152005</td>\n",
       "      <td>-0.033109</td>\n",
       "      <td>0.078383</td>\n",
       "      <td>0.057884</td>\n",
       "      <td>0.083841</td>\n",
       "      <td>-0.004646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E6</th>\n",
       "      <td>-0.034418</td>\n",
       "      <td>-0.003838</td>\n",
       "      <td>-0.189198</td>\n",
       "      <td>-0.004635</td>\n",
       "      <td>-0.006843</td>\n",
       "      <td>-0.004508</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>-0.006387</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>-0.105148</td>\n",
       "      <td>0.011380</td>\n",
       "      <td>0.044847</td>\n",
       "      <td>-0.165577</td>\n",
       "      <td>0.060057</td>\n",
       "      <td>0.014476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.248943</td>\n",
       "      <td>0.098840</td>\n",
       "      <td>-0.170502</td>\n",
       "      <td>0.011477</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>-0.049803</td>\n",
       "      <td>-0.037068</td>\n",
       "      <td>-0.005844</td>\n",
       "      <td>0.086723</td>\n",
       "      <td>0.013194</td>\n",
       "      <td>-0.043660</td>\n",
       "      <td>-0.031359</td>\n",
       "      <td>-0.046781</td>\n",
       "      <td>-0.009406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E7</th>\n",
       "      <td>-0.116919</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>-0.329722</td>\n",
       "      <td>-0.013194</td>\n",
       "      <td>-0.002058</td>\n",
       "      <td>-0.014086</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>-0.032576</td>\n",
       "      <td>-0.006923</td>\n",
       "      <td>-0.042634</td>\n",
       "      <td>0.114083</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>-0.075357</td>\n",
       "      <td>-0.202970</td>\n",
       "      <td>-0.035202</td>\n",
       "      <td>0.248943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.635992</td>\n",
       "      <td>-0.744275</td>\n",
       "      <td>0.312870</td>\n",
       "      <td>-0.031910</td>\n",
       "      <td>0.188332</td>\n",
       "      <td>0.020010</td>\n",
       "      <td>0.023965</td>\n",
       "      <td>-0.048397</td>\n",
       "      <td>-0.058715</td>\n",
       "      <td>0.186425</td>\n",
       "      <td>0.128932</td>\n",
       "      <td>0.157692</td>\n",
       "      <td>-0.004873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E8</th>\n",
       "      <td>-0.095434</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>-0.283440</td>\n",
       "      <td>-0.010918</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>-0.014135</td>\n",
       "      <td>0.012959</td>\n",
       "      <td>-0.048551</td>\n",
       "      <td>-0.008941</td>\n",
       "      <td>0.022973</td>\n",
       "      <td>0.092611</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>-0.119815</td>\n",
       "      <td>0.021078</td>\n",
       "      <td>0.098840</td>\n",
       "      <td>0.635992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.594516</td>\n",
       "      <td>0.311184</td>\n",
       "      <td>-0.016692</td>\n",
       "      <td>0.202976</td>\n",
       "      <td>0.036510</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>-0.074523</td>\n",
       "      <td>-0.077849</td>\n",
       "      <td>0.194538</td>\n",
       "      <td>0.126790</td>\n",
       "      <td>0.179493</td>\n",
       "      <td>-0.008762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E9</th>\n",
       "      <td>0.116988</td>\n",
       "      <td>-0.002779</td>\n",
       "      <td>0.380353</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.018113</td>\n",
       "      <td>-0.016615</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>-0.005549</td>\n",
       "      <td>0.045725</td>\n",
       "      <td>-0.066801</td>\n",
       "      <td>-0.003062</td>\n",
       "      <td>0.016521</td>\n",
       "      <td>0.156194</td>\n",
       "      <td>0.057401</td>\n",
       "      <td>-0.170502</td>\n",
       "      <td>-0.744275</td>\n",
       "      <td>-0.594516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.313360</td>\n",
       "      <td>0.031089</td>\n",
       "      <td>-0.129286</td>\n",
       "      <td>-0.009856</td>\n",
       "      <td>-0.021323</td>\n",
       "      <td>0.013255</td>\n",
       "      <td>0.063281</td>\n",
       "      <td>-0.128772</td>\n",
       "      <td>-0.093210</td>\n",
       "      <td>-0.111997</td>\n",
       "      <td>-0.019344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E10</th>\n",
       "      <td>-0.100521</td>\n",
       "      <td>-0.008684</td>\n",
       "      <td>-0.067051</td>\n",
       "      <td>0.004549</td>\n",
       "      <td>0.014589</td>\n",
       "      <td>-0.013289</td>\n",
       "      <td>0.010501</td>\n",
       "      <td>-0.074753</td>\n",
       "      <td>-0.034470</td>\n",
       "      <td>0.109924</td>\n",
       "      <td>0.176868</td>\n",
       "      <td>-0.001179</td>\n",
       "      <td>0.035559</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>0.037778</td>\n",
       "      <td>0.011477</td>\n",
       "      <td>0.312870</td>\n",
       "      <td>0.311184</td>\n",
       "      <td>-0.313360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031277</td>\n",
       "      <td>0.376850</td>\n",
       "      <td>0.075143</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>-0.292688</td>\n",
       "      <td>-0.188536</td>\n",
       "      <td>0.364547</td>\n",
       "      <td>0.225304</td>\n",
       "      <td>0.328938</td>\n",
       "      <td>0.068841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E11</th>\n",
       "      <td>0.073676</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.079002</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.007423</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>0.028216</td>\n",
       "      <td>-0.008939</td>\n",
       "      <td>0.084846</td>\n",
       "      <td>-0.088023</td>\n",
       "      <td>-0.052130</td>\n",
       "      <td>0.011117</td>\n",
       "      <td>-0.015727</td>\n",
       "      <td>0.039560</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>-0.031910</td>\n",
       "      <td>-0.016692</td>\n",
       "      <td>0.031089</td>\n",
       "      <td>-0.031277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.273714</td>\n",
       "      <td>-0.009588</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.056647</td>\n",
       "      <td>0.109642</td>\n",
       "      <td>-0.331563</td>\n",
       "      <td>-0.276242</td>\n",
       "      <td>-0.154770</td>\n",
       "      <td>0.023469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>-0.117728</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>-0.269967</td>\n",
       "      <td>-0.025763</td>\n",
       "      <td>0.011310</td>\n",
       "      <td>-0.011347</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>-0.054428</td>\n",
       "      <td>-0.024449</td>\n",
       "      <td>-0.043512</td>\n",
       "      <td>0.430603</td>\n",
       "      <td>0.094731</td>\n",
       "      <td>0.015578</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.079413</td>\n",
       "      <td>-0.049803</td>\n",
       "      <td>0.188332</td>\n",
       "      <td>0.202976</td>\n",
       "      <td>-0.129286</td>\n",
       "      <td>0.376850</td>\n",
       "      <td>-0.273714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173796</td>\n",
       "      <td>0.113710</td>\n",
       "      <td>-0.435652</td>\n",
       "      <td>-0.309047</td>\n",
       "      <td>0.937334</td>\n",
       "      <td>0.572335</td>\n",
       "      <td>0.910776</td>\n",
       "      <td>-0.095577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>0.065063</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>-0.050740</td>\n",
       "      <td>-0.021118</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>-0.006926</td>\n",
       "      <td>0.026232</td>\n",
       "      <td>-0.010418</td>\n",
       "      <td>0.025850</td>\n",
       "      <td>0.068999</td>\n",
       "      <td>0.029370</td>\n",
       "      <td>-0.046786</td>\n",
       "      <td>-0.002248</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>-0.037068</td>\n",
       "      <td>0.020010</td>\n",
       "      <td>0.036510</td>\n",
       "      <td>-0.009856</td>\n",
       "      <td>0.075143</td>\n",
       "      <td>-0.009588</td>\n",
       "      <td>0.173796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029865</td>\n",
       "      <td>-0.164682</td>\n",
       "      <td>-0.406453</td>\n",
       "      <td>0.179933</td>\n",
       "      <td>0.107099</td>\n",
       "      <td>0.153246</td>\n",
       "      <td>-0.043922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>-0.062000</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>-0.006380</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>-0.004996</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>0.045605</td>\n",
       "      <td>-0.003652</td>\n",
       "      <td>0.048736</td>\n",
       "      <td>-0.007556</td>\n",
       "      <td>-0.016252</td>\n",
       "      <td>-0.005844</td>\n",
       "      <td>0.023965</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>-0.021323</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.113710</td>\n",
       "      <td>-0.029865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094807</td>\n",
       "      <td>0.034938</td>\n",
       "      <td>0.110503</td>\n",
       "      <td>0.078252</td>\n",
       "      <td>0.128663</td>\n",
       "      <td>-0.000325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>-0.074320</td>\n",
       "      <td>-0.000480</td>\n",
       "      <td>0.097022</td>\n",
       "      <td>0.021404</td>\n",
       "      <td>-0.006038</td>\n",
       "      <td>0.013045</td>\n",
       "      <td>-0.010905</td>\n",
       "      <td>0.070290</td>\n",
       "      <td>0.019121</td>\n",
       "      <td>0.037711</td>\n",
       "      <td>-0.185484</td>\n",
       "      <td>-0.060586</td>\n",
       "      <td>0.140578</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>-0.152005</td>\n",
       "      <td>0.086723</td>\n",
       "      <td>-0.048397</td>\n",
       "      <td>-0.074523</td>\n",
       "      <td>0.013255</td>\n",
       "      <td>-0.292688</td>\n",
       "      <td>0.056647</td>\n",
       "      <td>-0.435652</td>\n",
       "      <td>-0.164682</td>\n",
       "      <td>0.094807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087289</td>\n",
       "      <td>-0.405763</td>\n",
       "      <td>-0.250265</td>\n",
       "      <td>-0.386108</td>\n",
       "      <td>0.081574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.123721</td>\n",
       "      <td>-0.006284</td>\n",
       "      <td>0.055429</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>-0.023902</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>-0.016671</td>\n",
       "      <td>0.029222</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>-0.114477</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>-0.079563</td>\n",
       "      <td>-0.006332</td>\n",
       "      <td>-0.033109</td>\n",
       "      <td>0.013194</td>\n",
       "      <td>-0.058715</td>\n",
       "      <td>-0.077849</td>\n",
       "      <td>0.063281</td>\n",
       "      <td>-0.188536</td>\n",
       "      <td>0.109642</td>\n",
       "      <td>-0.309047</td>\n",
       "      <td>-0.406453</td>\n",
       "      <td>0.034938</td>\n",
       "      <td>0.087289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.276837</td>\n",
       "      <td>-0.162438</td>\n",
       "      <td>-0.244230</td>\n",
       "      <td>0.033800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>-0.097389</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>-0.244150</td>\n",
       "      <td>-0.019792</td>\n",
       "      <td>0.010608</td>\n",
       "      <td>-0.010245</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>-0.046353</td>\n",
       "      <td>-0.025728</td>\n",
       "      <td>-0.020696</td>\n",
       "      <td>0.399214</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.078383</td>\n",
       "      <td>-0.043660</td>\n",
       "      <td>0.186425</td>\n",
       "      <td>0.194538</td>\n",
       "      <td>-0.128772</td>\n",
       "      <td>0.364547</td>\n",
       "      <td>-0.331563</td>\n",
       "      <td>0.937334</td>\n",
       "      <td>0.179933</td>\n",
       "      <td>0.110503</td>\n",
       "      <td>-0.405763</td>\n",
       "      <td>-0.276837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658544</td>\n",
       "      <td>0.822076</td>\n",
       "      <td>-0.089677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>-0.047593</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>-0.165550</td>\n",
       "      <td>-0.029747</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>-0.007963</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>-0.023359</td>\n",
       "      <td>-0.016850</td>\n",
       "      <td>-0.008450</td>\n",
       "      <td>0.227876</td>\n",
       "      <td>0.044731</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>-0.014779</td>\n",
       "      <td>0.057884</td>\n",
       "      <td>-0.031359</td>\n",
       "      <td>0.128932</td>\n",
       "      <td>0.126790</td>\n",
       "      <td>-0.093210</td>\n",
       "      <td>0.225304</td>\n",
       "      <td>-0.276242</td>\n",
       "      <td>0.572335</td>\n",
       "      <td>0.107099</td>\n",
       "      <td>0.078252</td>\n",
       "      <td>-0.250265</td>\n",
       "      <td>-0.162438</td>\n",
       "      <td>0.658544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513956</td>\n",
       "      <td>-0.056313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>-0.093818</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>-0.259607</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>-0.009630</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>-0.022193</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>0.382013</td>\n",
       "      <td>0.081133</td>\n",
       "      <td>0.042666</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.083841</td>\n",
       "      <td>-0.046781</td>\n",
       "      <td>0.157692</td>\n",
       "      <td>0.179493</td>\n",
       "      <td>-0.111997</td>\n",
       "      <td>0.328938</td>\n",
       "      <td>-0.154770</td>\n",
       "      <td>0.910776</td>\n",
       "      <td>0.153246</td>\n",
       "      <td>0.128663</td>\n",
       "      <td>-0.386108</td>\n",
       "      <td>-0.244230</td>\n",
       "      <td>0.822076</td>\n",
       "      <td>0.513956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>0.078887</td>\n",
       "      <td>-0.011465</td>\n",
       "      <td>0.155722</td>\n",
       "      <td>0.344636</td>\n",
       "      <td>-0.034248</td>\n",
       "      <td>-0.009808</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>-0.004897</td>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.019360</td>\n",
       "      <td>-0.070397</td>\n",
       "      <td>-0.061395</td>\n",
       "      <td>0.115566</td>\n",
       "      <td>-0.003311</td>\n",
       "      <td>-0.004646</td>\n",
       "      <td>-0.009406</td>\n",
       "      <td>-0.004873</td>\n",
       "      <td>-0.008762</td>\n",
       "      <td>-0.019344</td>\n",
       "      <td>0.068841</td>\n",
       "      <td>0.023469</td>\n",
       "      <td>-0.095577</td>\n",
       "      <td>-0.043922</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>0.081574</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>-0.089677</td>\n",
       "      <td>-0.056313</td>\n",
       "      <td>-0.055327</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TrialID    ObsNum   IsAlert        P1        P2        P3        P4  \\\n",
       "TrialID  1.000000 -0.000162 -0.145816  0.016772 -0.004473  0.000369  0.001880   \n",
       "ObsNum  -0.000162  1.000000 -0.005143  0.018324 -0.001764  0.002199 -0.001191   \n",
       "IsAlert -0.145816 -0.005143  1.000000  0.018361  0.014383  0.005168 -0.008177   \n",
       "P1       0.016772  0.018324  0.018361  1.000000 -0.006674 -0.010317  0.011704   \n",
       "P2      -0.004473 -0.001764  0.014383 -0.006674  1.000000 -0.002539  0.002132   \n",
       "P3       0.000369  0.002199  0.005168 -0.010317 -0.002539  1.000000 -0.944435   \n",
       "P4       0.001880 -0.001191 -0.008177  0.011704  0.002132 -0.944435  1.000000   \n",
       "P5       0.022632  0.005568  0.038160  0.010911  0.008390  0.035129 -0.032897   \n",
       "P6       0.005377 -0.015791 -0.000400  0.045429 -0.022003  0.012444 -0.010627   \n",
       "P7       0.111903  0.003498  0.189796  0.027461  0.052171 -0.006097  0.007323   \n",
       "E1      -0.061881 -0.000122 -0.160830 -0.015436 -0.012045  0.005795 -0.004870   \n",
       "E2       0.015610 -0.003558 -0.105495 -0.009356 -0.019121  0.013007 -0.010749   \n",
       "E3      -0.087071  0.002931  0.157973  0.024131  0.062076 -0.016437  0.010696   \n",
       "E4      -0.050151 -0.004580  0.047992 -0.010574  0.003529  0.000515  0.001580   \n",
       "E5       0.234524  0.010314 -0.067453 -0.006564 -0.005140  0.004496 -0.003086   \n",
       "E6      -0.034418 -0.003838 -0.189198 -0.004635 -0.006843 -0.004508  0.004230   \n",
       "E7      -0.116919  0.002005 -0.329722 -0.013194 -0.002058 -0.014086  0.013755   \n",
       "E8      -0.095434  0.009400 -0.283440 -0.010918  0.002920 -0.014135  0.012959   \n",
       "E9       0.116988 -0.002779  0.380353  0.004688  0.002266  0.018113 -0.016615   \n",
       "E10     -0.100521 -0.008684 -0.067051  0.004549  0.014589 -0.013289  0.010501   \n",
       "E11      0.073676  0.004978  0.079002  0.015882  0.001857  0.007423 -0.005681   \n",
       "V1      -0.117728  0.004242 -0.269967 -0.025763  0.011310 -0.011347  0.010061   \n",
       "V2       0.065063  0.019009 -0.050740 -0.021118  0.001779  0.008651 -0.006926   \n",
       "V3       0.001900  0.007753 -0.062000  0.002551  0.002272 -0.006380  0.008049   \n",
       "V4      -0.074320 -0.000480  0.097022  0.021404 -0.006038  0.013045 -0.010905   \n",
       "V5       0.123721 -0.006284  0.055429  0.051348 -0.023902  0.001312  0.001705   \n",
       "V6      -0.097389  0.003935 -0.244150 -0.019792  0.010608 -0.010245  0.008348   \n",
       "V8      -0.047593  0.008191 -0.165550 -0.029747  0.008257 -0.007963  0.005379   \n",
       "V10     -0.093818  0.005145 -0.259607 -0.004563  0.001946 -0.009630  0.008906   \n",
       "V11      0.078887 -0.011465  0.155722  0.344636 -0.034248 -0.009808  0.009841   \n",
       "\n",
       "               P5        P6        P7        E1        E2        E3        E4  \\\n",
       "TrialID  0.022632  0.005377  0.111903 -0.061881  0.015610 -0.087071 -0.050151   \n",
       "ObsNum   0.005568 -0.015791  0.003498 -0.000122 -0.003558  0.002931 -0.004580   \n",
       "IsAlert  0.038160 -0.000400  0.189796 -0.160830 -0.105495  0.157973  0.047992   \n",
       "P1       0.010911  0.045429  0.027461 -0.015436 -0.009356  0.024131 -0.010574   \n",
       "P2       0.008390 -0.022003  0.052171 -0.012045 -0.019121  0.062076  0.003529   \n",
       "P3       0.035129  0.012444 -0.006097  0.005795  0.013007 -0.016437  0.000515   \n",
       "P4      -0.032897 -0.010627  0.007323 -0.004870 -0.010749  0.010696  0.001580   \n",
       "P5       1.000000  0.002314 -0.023628 -0.062955 -0.033420  0.069444 -0.002757   \n",
       "P6       0.002314  1.000000 -0.125580 -0.006273  0.006025 -0.025157 -0.001288   \n",
       "P7      -0.023628 -0.125580  1.000000 -0.087373 -0.091327  0.294528  0.026627   \n",
       "E1      -0.062955 -0.006273 -0.087373  1.000000  0.725684 -0.210994 -0.001312   \n",
       "E2      -0.033420  0.006025 -0.091327  0.725684  1.000000 -0.230564 -0.003982   \n",
       "E3       0.069444 -0.025157  0.294528 -0.210994 -0.230564  1.000000  0.016046   \n",
       "E4      -0.002757 -0.001288  0.026627 -0.001312 -0.003982  0.016046  1.000000   \n",
       "E5      -0.020218 -0.007514  0.051338  0.046620  0.041188 -0.121065  0.118974   \n",
       "E6      -0.006387  0.011529 -0.105148  0.011380  0.044847 -0.165577  0.060057   \n",
       "E7      -0.032576 -0.006923 -0.042634  0.114083  0.040890 -0.075357 -0.202970   \n",
       "E8      -0.048551 -0.008941  0.022973  0.092611  0.011876  0.000226 -0.119815   \n",
       "E9       0.005177 -0.005549  0.045725 -0.066801 -0.003062  0.016521  0.156194   \n",
       "E10     -0.074753 -0.034470  0.109924  0.176868 -0.001179  0.035559  0.013668   \n",
       "E11      0.028216 -0.008939  0.084846 -0.088023 -0.052130  0.011117 -0.015727   \n",
       "V1      -0.054428 -0.024449 -0.043512  0.430603  0.094731  0.015578  0.002181   \n",
       "V2       0.026232 -0.010418  0.025850  0.068999  0.029370 -0.046786 -0.002248   \n",
       "V3       0.005371 -0.004996  0.007986  0.045605 -0.003652  0.048736 -0.007556   \n",
       "V4       0.070290  0.019121  0.037711 -0.185484 -0.060586  0.140578  0.009405   \n",
       "V5      -0.016671  0.029222  0.024499 -0.114477  0.001465 -0.079563 -0.006332   \n",
       "V6      -0.046353 -0.025728 -0.020696  0.399214  0.083946  0.006129 -0.004937   \n",
       "V8      -0.023359 -0.016850 -0.008450  0.227876  0.044731  0.012401 -0.014779   \n",
       "V10     -0.022193 -0.002163 -0.041814  0.382013  0.081133  0.042666  0.000264   \n",
       "V11     -0.004897  0.012783  0.019360 -0.070397 -0.061395  0.115566 -0.003311   \n",
       "\n",
       "               E5        E6        E7        E8        E9       E10       E11  \\\n",
       "TrialID  0.234524 -0.034418 -0.116919 -0.095434  0.116988 -0.100521  0.073676   \n",
       "ObsNum   0.010314 -0.003838  0.002005  0.009400 -0.002779 -0.008684  0.004978   \n",
       "IsAlert -0.067453 -0.189198 -0.329722 -0.283440  0.380353 -0.067051  0.079002   \n",
       "P1      -0.006564 -0.004635 -0.013194 -0.010918  0.004688  0.004549  0.015882   \n",
       "P2      -0.005140 -0.006843 -0.002058  0.002920  0.002266  0.014589  0.001857   \n",
       "P3       0.004496 -0.004508 -0.014086 -0.014135  0.018113 -0.013289  0.007423   \n",
       "P4      -0.003086  0.004230  0.013755  0.012959 -0.016615  0.010501 -0.005681   \n",
       "P5      -0.020218 -0.006387 -0.032576 -0.048551  0.005177 -0.074753  0.028216   \n",
       "P6      -0.007514  0.011529 -0.006923 -0.008941 -0.005549 -0.034470 -0.008939   \n",
       "P7       0.051338 -0.105148 -0.042634  0.022973  0.045725  0.109924  0.084846   \n",
       "E1       0.046620  0.011380  0.114083  0.092611 -0.066801  0.176868 -0.088023   \n",
       "E2       0.041188  0.044847  0.040890  0.011876 -0.003062 -0.001179 -0.052130   \n",
       "E3      -0.121065 -0.165577 -0.075357  0.000226  0.016521  0.035559  0.011117   \n",
       "E4       0.118974  0.060057 -0.202970 -0.119815  0.156194  0.013668 -0.015727   \n",
       "E5       1.000000  0.014476 -0.035202  0.021078  0.057401  0.037778  0.039560   \n",
       "E6       0.014476  1.000000  0.248943  0.098840 -0.170502  0.011477  0.001127   \n",
       "E7      -0.035202  0.248943  1.000000  0.635992 -0.744275  0.312870 -0.031910   \n",
       "E8       0.021078  0.098840  0.635992  1.000000 -0.594516  0.311184 -0.016692   \n",
       "E9       0.057401 -0.170502 -0.744275 -0.594516  1.000000 -0.313360  0.031089   \n",
       "E10      0.037778  0.011477  0.312870  0.311184 -0.313360  1.000000 -0.031277   \n",
       "E11      0.039560  0.001127 -0.031910 -0.016692  0.031089 -0.031277  1.000000   \n",
       "V1       0.079413 -0.049803  0.188332  0.202976 -0.129286  0.376850 -0.273714   \n",
       "V2       0.025036 -0.037068  0.020010  0.036510 -0.009856  0.075143 -0.009588   \n",
       "V3      -0.016252 -0.005844  0.023965  0.025184 -0.021323  0.014493  0.023545   \n",
       "V4      -0.152005  0.086723 -0.048397 -0.074523  0.013255 -0.292688  0.056647   \n",
       "V5      -0.033109  0.013194 -0.058715 -0.077849  0.063281 -0.188536  0.109642   \n",
       "V6       0.078383 -0.043660  0.186425  0.194538 -0.128772  0.364547 -0.331563   \n",
       "V8       0.057884 -0.031359  0.128932  0.126790 -0.093210  0.225304 -0.276242   \n",
       "V10      0.083841 -0.046781  0.157692  0.179493 -0.111997  0.328938 -0.154770   \n",
       "V11     -0.004646 -0.009406 -0.004873 -0.008762 -0.019344  0.068841  0.023469   \n",
       "\n",
       "               V1        V2        V3        V4        V5        V6        V8  \\\n",
       "TrialID -0.117728  0.065063  0.001900 -0.074320  0.123721 -0.097389 -0.047593   \n",
       "ObsNum   0.004242  0.019009  0.007753 -0.000480 -0.006284  0.003935  0.008191   \n",
       "IsAlert -0.269967 -0.050740 -0.062000  0.097022  0.055429 -0.244150 -0.165550   \n",
       "P1      -0.025763 -0.021118  0.002551  0.021404  0.051348 -0.019792 -0.029747   \n",
       "P2       0.011310  0.001779  0.002272 -0.006038 -0.023902  0.010608  0.008257   \n",
       "P3      -0.011347  0.008651 -0.006380  0.013045  0.001312 -0.010245 -0.007963   \n",
       "P4       0.010061 -0.006926  0.008049 -0.010905  0.001705  0.008348  0.005379   \n",
       "P5      -0.054428  0.026232  0.005371  0.070290 -0.016671 -0.046353 -0.023359   \n",
       "P6      -0.024449 -0.010418 -0.004996  0.019121  0.029222 -0.025728 -0.016850   \n",
       "P7      -0.043512  0.025850  0.007986  0.037711  0.024499 -0.020696 -0.008450   \n",
       "E1       0.430603  0.068999  0.045605 -0.185484 -0.114477  0.399214  0.227876   \n",
       "E2       0.094731  0.029370 -0.003652 -0.060586  0.001465  0.083946  0.044731   \n",
       "E3       0.015578 -0.046786  0.048736  0.140578 -0.079563  0.006129  0.012401   \n",
       "E4       0.002181 -0.002248 -0.007556  0.009405 -0.006332 -0.004937 -0.014779   \n",
       "E5       0.079413  0.025036 -0.016252 -0.152005 -0.033109  0.078383  0.057884   \n",
       "E6      -0.049803 -0.037068 -0.005844  0.086723  0.013194 -0.043660 -0.031359   \n",
       "E7       0.188332  0.020010  0.023965 -0.048397 -0.058715  0.186425  0.128932   \n",
       "E8       0.202976  0.036510  0.025184 -0.074523 -0.077849  0.194538  0.126790   \n",
       "E9      -0.129286 -0.009856 -0.021323  0.013255  0.063281 -0.128772 -0.093210   \n",
       "E10      0.376850  0.075143  0.014493 -0.292688 -0.188536  0.364547  0.225304   \n",
       "E11     -0.273714 -0.009588  0.023545  0.056647  0.109642 -0.331563 -0.276242   \n",
       "V1       1.000000  0.173796  0.113710 -0.435652 -0.309047  0.937334  0.572335   \n",
       "V2       0.173796  1.000000 -0.029865 -0.164682 -0.406453  0.179933  0.107099   \n",
       "V3       0.113710 -0.029865  1.000000  0.094807  0.034938  0.110503  0.078252   \n",
       "V4      -0.435652 -0.164682  0.094807  1.000000  0.087289 -0.405763 -0.250265   \n",
       "V5      -0.309047 -0.406453  0.034938  0.087289  1.000000 -0.276837 -0.162438   \n",
       "V6       0.937334  0.179933  0.110503 -0.405763 -0.276837  1.000000  0.658544   \n",
       "V8       0.572335  0.107099  0.078252 -0.250265 -0.162438  0.658544  1.000000   \n",
       "V10      0.910776  0.153246  0.128663 -0.386108 -0.244230  0.822076  0.513956   \n",
       "V11     -0.095577 -0.043922 -0.000325  0.081574  0.033800 -0.089677 -0.056313   \n",
       "\n",
       "              V10       V11  \n",
       "TrialID -0.093818  0.078887  \n",
       "ObsNum   0.005145 -0.011465  \n",
       "IsAlert -0.259607  0.155722  \n",
       "P1      -0.004563  0.344636  \n",
       "P2       0.001946 -0.034248  \n",
       "P3      -0.009630 -0.009808  \n",
       "P4       0.008906  0.009841  \n",
       "P5      -0.022193 -0.004897  \n",
       "P6      -0.002163  0.012783  \n",
       "P7      -0.041814  0.019360  \n",
       "E1       0.382013 -0.070397  \n",
       "E2       0.081133 -0.061395  \n",
       "E3       0.042666  0.115566  \n",
       "E4       0.000264 -0.003311  \n",
       "E5       0.083841 -0.004646  \n",
       "E6      -0.046781 -0.009406  \n",
       "E7       0.157692 -0.004873  \n",
       "E8       0.179493 -0.008762  \n",
       "E9      -0.111997 -0.019344  \n",
       "E10      0.328938  0.068841  \n",
       "E11     -0.154770  0.023469  \n",
       "V1       0.910776 -0.095577  \n",
       "V2       0.153246 -0.043922  \n",
       "V3       0.128663 -0.000325  \n",
       "V4      -0.386108  0.081574  \n",
       "V5      -0.244230  0.033800  \n",
       "V6       0.822076 -0.089677  \n",
       "V8       0.513956 -0.056313  \n",
       "V10      1.000000 -0.055327  \n",
       "V11     -0.055327  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1 = train.drop(['P8','V7','V9'],axis =1)\n",
    "\n",
    "#correlation\n",
    "numerics = ['int16','int32','int64','float16','float32','float64']\n",
    "newdf = train_1.select_dtypes(include = numerics)\n",
    "newdf.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialID     0.024138\n",
       "ObsNum      0.000214\n",
       "IsAlert    -0.319185\n",
       "P1          2.445986\n",
       "P2          0.863450\n",
       "P3          0.507984\n",
       "P4          0.643117\n",
       "P5         20.225034\n",
       "P6         89.789752\n",
       "P7          1.937124\n",
       "E1          0.766075\n",
       "E2          0.754220\n",
       "E3          3.352342\n",
       "E4         -2.467771\n",
       "E5          0.175100\n",
       "E6         -0.469872\n",
       "E7          2.844119\n",
       "E8          2.200218\n",
       "E9         -2.292728\n",
       "E10        -0.433540\n",
       "E11         4.062888\n",
       "V1         -0.941470\n",
       "V2         -0.759452\n",
       "V3          0.261053\n",
       "V4          5.144928\n",
       "V5          1.667496\n",
       "V6         -0.871827\n",
       "V8          0.406715\n",
       "V10        -1.172114\n",
       "V11        21.165566\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_1.iloc[:,3:30]\n",
    "y = train_1['IsAlert']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    349785\n",
       "0    254544\n",
       "Name: IsAlert, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1['IsAlert'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>IsAlert</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51346</td>\n",
       "      <td>4274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12466</td>\n",
       "      <td>82997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "IsAlert      0      1\n",
       "row_0                \n",
       "0        51346   4274\n",
       "1        12466  82997"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "mod = XGBClassifier()\n",
    "mod.fit(x_train,y_train)\n",
    "preds_y_xg = mod.predict(x_test)\n",
    "pd.crosstab(preds_y_xg,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>IsAlert</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45357</td>\n",
       "      <td>13749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18455</td>\n",
       "      <td>73522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "IsAlert      0      1\n",
       "row_0                \n",
       "0        45357  13749\n",
       "1        18455  73522"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train,y_train)\n",
    "preds_y1_log = log_reg.predict(x_train)\n",
    "preds_y_log = log_reg.predict(x_test)\n",
    "pd.crosstab(preds_y_log,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.776978474344612"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_y1_log = log_reg.predict(x_train)\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr ,tpr ,thresholds = metrics.roc_curve(y_train,preds_y1_log)\n",
    "\n",
    "metrics.auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8776941052380828"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_y1_xg = mod.predict(x_train)\n",
    "fpr ,tpr ,thresholds = metrics.roc_curve(y_train,preds_y1_xg)\n",
    "metrics.auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>IsAlert</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62727</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1085</td>\n",
       "      <td>86270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "IsAlert      0      1\n",
       "row_0                \n",
       "0        62727   1001\n",
       "1         1085  86270"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state = 0)\n",
    "dt.fit(x_train,y_train)\n",
    "preds_y_dec = dt.predict(x_test)\n",
    "pd.crosstab(preds_y_dec,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsAlert</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63012</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292</td>\n",
       "      <td>86979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        0      1\n",
       "IsAlert              \n",
       "0        63012    800\n",
       "1          292  86979"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_y_rand = clf.predict(x_test)\n",
    "pd.crosstab(y_test,preds_y_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialID        int64\n",
       "ObsNum         int64\n",
       "Prediction     int64\n",
       "Indicator     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = pd.read_csv(\"Solution.csv\")\n",
    "test2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"fordTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialID      int64\n",
       "ObsNum       int64\n",
       "IsAlert     object\n",
       "P1         float64\n",
       "P2         float64\n",
       "P3           int64\n",
       "P4         float64\n",
       "P5         float64\n",
       "P6           int64\n",
       "P7         float64\n",
       "P8           int64\n",
       "E1         float64\n",
       "E2         float64\n",
       "E3           int64\n",
       "E4           int64\n",
       "E5         float64\n",
       "E6           int64\n",
       "E7           int64\n",
       "E8           int64\n",
       "E9           int64\n",
       "E10          int64\n",
       "E11        float64\n",
       "V1         float64\n",
       "V2         float64\n",
       "V3           int64\n",
       "V4         float64\n",
       "V5           int64\n",
       "V6           int64\n",
       "V7           int64\n",
       "V8         float64\n",
       "V9           int64\n",
       "V10          int64\n",
       "V11        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialID      int64\n",
       "ObsNum       int64\n",
       "IsAlert     object\n",
       "P1         float64\n",
       "P2         float64\n",
       "P3           int64\n",
       "P4         float64\n",
       "P5         float64\n",
       "P6           int64\n",
       "P7         float64\n",
       "E1         float64\n",
       "E2         float64\n",
       "E3           int64\n",
       "E4           int64\n",
       "E5         float64\n",
       "E6           int64\n",
       "E7           int64\n",
       "E8           int64\n",
       "E9           int64\n",
       "E10          int64\n",
       "E11        float64\n",
       "V1         float64\n",
       "V2         float64\n",
       "V3           int64\n",
       "V4         float64\n",
       "V5           int64\n",
       "V6           int64\n",
       "V8         float64\n",
       "V10          int64\n",
       "V11        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = test.drop(['P8','V7','V9'],axis = 1)\n",
    "test_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest1 = test_1.iloc[:,3:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ddd00abcb7e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxtest1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'IsAlert'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "xtest1['IsAlert'] = clf.predict(xtest1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsAlert</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17760</td>\n",
       "      <td>13869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12154</td>\n",
       "      <td>77057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction      0      1\n",
       "IsAlert                 \n",
       "0           17760  13869\n",
       "1           12154  77057"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(xtest1['IsAlert'],test2['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V8', 'V10', 'V11'] ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V8', 'V10', 'V11', 'IsAlert']\ntraining data did not have the following fields: IsAlert",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-fef55f55f277>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxtest1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'IsAlert1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m####Accuracy of xgboost algorithm is 81%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'IsAlert1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Prediction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[0;32m    789\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m                                                  validate_features=validate_features)\n\u001b[0m\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[1;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1284\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 1690\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   1691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V8', 'V10', 'V11'] ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V8', 'V10', 'V11', 'IsAlert']\ntraining data did not have the following fields: IsAlert"
     ]
    }
   ],
   "source": [
    "xtest1['IsAlert1'] = mod.predict(xtest1)####Accuracy of xgboost algorithm is 81%\n",
    "pd.crosstab(xtest1['IsAlert1'],test2['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest1['IsAlert2'] = dt.predict(xtest1)##Accuracy of decision tree is 72%\n",
    "pd.crosstab(xtest1['IsAlert2'],test2['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# fpr , tpr, thresholds = metrics.roc_curve(y_test,preds_y_dec)\n",
    "# metrics.auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest1['IsAlert3'] = clf.predict(xtest1)#####Random forest accuracy is 78%#########\n",
    "pd.crosstab(xtest1['IsAlert3'],test2['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###bootstrapping is subsampling data\n",
    "#1 - 5 is one sample and sample inside sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier()\n",
    "nn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_y_nn = nn.predict(x_test)\n",
    "pd.crosstab(preds_y_nn,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_y_f = nn.predict(xtest1)\n",
    "pd.crosstab(preds_y_f,test2['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(random_state= 0)\n",
    "ada.fit(x_train,y_train)\n",
    "preds_y_ada = ada.predict(xtest1)\n",
    "pd.crosstab(preds_y_ada,test2['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svm_1 = svm.SVC(gamma = 'scale')\n",
    "svm_1.fit(x_train,y_train)\n",
    "preds_y_svm = svm_1.predict(xtest1)\n",
    "pd.crosstab(preds_y_svm,test2['Prediction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVC = SVC()\n",
    "SVC.fit(x_train,y_train)\n",
    "y23 = SVC.predict(xtest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y23,test2['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
