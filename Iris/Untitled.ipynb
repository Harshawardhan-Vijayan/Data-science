{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "train = pd.DataFrame(iris.data)\n",
    "train.columns = iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "1                  4.9               3.0                1.4               0.2\n",
      "2                  4.7               3.2                1.3               0.2\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "4                  5.0               3.6                1.4               0.2\n",
      "5                  5.4               3.9                1.7               0.4\n",
      "6                  4.6               3.4                1.4               0.3\n",
      "7                  5.0               3.4                1.5               0.2\n",
      "8                  4.4               2.9                1.4               0.2\n",
      "9                  4.9               3.1                1.5               0.1\n",
      "10                 5.4               3.7                1.5               0.2\n",
      "11                 4.8               3.4                1.6               0.2\n",
      "12                 4.8               3.0                1.4               0.1\n",
      "13                 4.3               3.0                1.1               0.1\n",
      "14                 5.8               4.0                1.2               0.2\n",
      "15                 5.7               4.4                1.5               0.4\n",
      "16                 5.4               3.9                1.3               0.4\n",
      "17                 5.1               3.5                1.4               0.3\n",
      "18                 5.7               3.8                1.7               0.3\n",
      "19                 5.1               3.8                1.5               0.3\n",
      "20                 5.4               3.4                1.7               0.2\n",
      "21                 5.1               3.7                1.5               0.4\n",
      "22                 4.6               3.6                1.0               0.2\n",
      "23                 5.1               3.3                1.7               0.5\n",
      "24                 4.8               3.4                1.9               0.2\n",
      "25                 5.0               3.0                1.6               0.2\n",
      "26                 5.0               3.4                1.6               0.4\n",
      "27                 5.2               3.5                1.5               0.2\n",
      "28                 5.2               3.4                1.4               0.2\n",
      "29                 4.7               3.2                1.6               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "120                6.9               3.2                5.7               2.3\n",
      "121                5.6               2.8                4.9               2.0\n",
      "122                7.7               2.8                6.7               2.0\n",
      "123                6.3               2.7                4.9               1.8\n",
      "124                6.7               3.3                5.7               2.1\n",
      "125                7.2               3.2                6.0               1.8\n",
      "126                6.2               2.8                4.8               1.8\n",
      "127                6.1               3.0                4.9               1.8\n",
      "128                6.4               2.8                5.6               2.1\n",
      "129                7.2               3.0                5.8               1.6\n",
      "130                7.4               2.8                6.1               1.9\n",
      "131                7.9               3.8                6.4               2.0\n",
      "132                6.4               2.8                5.6               2.2\n",
      "133                6.3               2.8                5.1               1.5\n",
      "134                6.1               2.6                5.6               1.4\n",
      "135                7.7               3.0                6.1               2.3\n",
      "136                6.3               3.4                5.6               2.4\n",
      "137                6.4               3.1                5.5               1.8\n",
      "138                6.0               3.0                4.8               1.8\n",
      "139                6.9               3.1                5.4               2.1\n",
      "140                6.7               3.1                5.6               2.4\n",
      "141                6.9               3.1                5.1               2.3\n",
      "142                5.8               2.7                5.1               1.9\n",
      "143                6.8               3.2                5.9               2.3\n",
      "144                6.7               3.3                5.7               2.5\n",
      "145                6.7               3.0                5.2               2.3\n",
      "146                6.3               2.5                5.0               1.9\n",
      "147                6.5               3.0                5.2               2.0\n",
      "148                6.2               3.4                5.4               2.3\n",
      "149                5.9               3.0                5.1               1.8\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZxcZZ3v8c+3t/SWvTosCSEdiLi9ZDFs4iCIzgijwszI4I6Kcr2DI3odR1zmXr0zzuh4x4VRURQlKK4oggqMiCziAJogm4IkJIGEAOnsSyfd6e7f/eM83akkne6q0NVV1fV9v171qjrPOXXqV5VO/ep5zrMoIjAzMwOoK3cAZmZWOZwUzMxsiJOCmZkNcVIwM7MhTgpmZjbEScHMzIY4KVhRJL1N0p152yHpyHLGNFbG8r1IWinpFfvZ1yLpp5I2S/rhWLxeKUj6iKSvl+jcI30+V0r6l1K8ro3OScH2kf7D7pC0Le/2xXLHBUNJKSR9dq/yc1L5lQWe5zZJ7yxJkKN7HXAQMDMizh2LE0qaJukySU9L6pb0oKS3F/H80yStzi+LiH+NiHJ9RlYmDeUOwCrWayLil+UOYj8eA86T9I8R0ZfK3go8WsaYinE48Ghe7AWT1LD38yQ1Ab8E1gInA6uBM4BFkqZHxGf3PZPZ8FxTsLFwlqTlktZJ+oykOgBJdZI+JulxSWslXSVpatq3SNIH0uPZ6Vf+36XtIyVtkKT9vN7TwIPAX6TjZwAvAa7PP0jSSZL+W9ImSfdLOi2VfxL4M+CLw9SCXiFpqaSNkr40GMNI7yXtf0vat17SR/f3QUn6BPC/yZLaNkkXjPI5zUufzQWSngB+Ncxp3wLMBc6NiBURsSsibgLeC/xfSVPSuVZK+rCkP6b3901JzZLagBuBQ/NqhodK+rikb+8Vx9slrUrPf7ek4yU9kD7joc9R0hGSfpU+j3WSrpY0bX+fywif12RJt0q6dIS/BxtDTgo2Fv4KWAgcB5wNvCOVvy3dTgfmA+3A4BfH7cBp6fHLgOXpHuBU4Ncx8hwsV5HVDgBeD1wH9AzulDQb+DnwL8AM4B+AH0nqiIiPAr8G3hMR7RHxnrzzvho4Hjga+FtS4hnpvUh6PnAZ2ZfzocBMYM5wQUfE/wH+Ffh+eu0rRvmcBr0MeF5ePPleCdwYEdv3Kv8R0ExWexj0pnSOI4DnAB9LzzsTWJNiao+INcPFD5wILADOAz4PfBR4BfAC4G8lDf4bCvi39Hk8DzgM+Ph+zjksSTOBW4DfRMR7R/l7sDHipGD785P062/w9q4Rjv10RGyIiCfIvijekMrfBHw2IpZHxDbgw8DrJTWQJYU/S7WKU4F/B05Jz3tZ2j+Sa4HT0i/qt5IliXxvBm6IiBsiYiAibgYWA2eNct5PRcSm9F5uBY4p4L28DvhZRNwRET3APwEDo7xOvpHOPejjEbE9InYM8/wc8NTehamZaV3aP+iLEbEqIjYAn2T3v1Wh/jkidkbEL4DtwHcjYm1EPEmWaI9Nr70sIm6OiJ6I6AI+y+6kX4hDyf4GfhgRHysyRnsWnBRsf86JiGl5t6+NcOyqvMePk/2HJt0/vte+BuCgiHgM2Eb2pftnwM+ANZKOooCkkL4cfw58DMhFxG/2OuRw4Nz8xAa8FDhkpPOSNU0N6ib71T7ie0n7hj6D9Mt7/Sivk2+kcw9axf6tY5j3lZJKLu0f7jz5/1aFeibv8Y5httvTa8+S9D1JT0raAnybPZPTaP4SaAG+UmR89iw5KdhYOCzv8VxgsOlhDdmXc/6+PnZ/kdxO9iu7Kf3SvJ3sV/904L4CXvcq4APAt4bZtwr41l6JrS0iPpX2F9sUMdJ7eYq8z0BSK1kT0lice9BI8f4SODNdG8j3N2RNanfnle3v32qsm2b+LZ3zRRExhazmVsw1ga8BNwE3DPO+rIScFGwsfFDSdEmHARcD30/l3wXeL6lTUju729IHe8/cDrwHuCNt3wb8PXBnRPQX8Lq3k7Wn/+cw+74NvEbSX0iqTxdUT5M02Nb/DFn7faFGei/XAK+W9FJlPYH+L8X93xrtcxrNt8h6HP0wXRBulPQXwKVkzU6b8469SNKcdHH+I+z+t3oGmJl/8fxZmkxWE9yUru988ADO8R7gT8DPJLWMUVw2CicF25+fas9xCteOcOx1wBKyX/c/B65I5d8g+8K6A1gB7CT70h90O9mXx2BSuBNozdseUWRuSe3je+9bRXbR+yNAF1nN4YPs/pv/AvC61Ivm0gJebr/vJSL+AFwEfIes1rCR7Eu6UKN9TiNK1zFeQfYe7wG2kLXhfzQiPrPX4d8BfkF2YX852YV4IuIRsuS0PDW3FdustLdPkHU82Ez2N/HjYk+QLixfSPa+rpPU/CxjsgLIF/TNaoOklcA7K3j8iVUA1xTMzGyIk4KZmQ1x85GZmQ1xTcHMzIZU/YR4uVwu5s2bV+4wzMyqypIlS9ZFRMfe5VWfFObNm8fixYvLHYaZWVWR9Phw5SVtPpJ0lKT78m5bJL1P0gxJNyubjfJmSdPT8UqzIS5LMy8eV8r4zMxsTyVNChHxp4g4JiKOAV5MNpfMtcAlwC0RsYBsFsRL0lPOJJuBcQHZoJXLShmfmZntaTwvNJ8BPBYRj5ONNF2UyhcB56THZwNXpZGqdwPTJI02gZmZmY2R8UwKrycbRg/ZLJlPAaT7Wal8NnvO4rg6le1B0oWSFkta3NXVVcKQzcxqy7gkhTRJ2GuB0RYpH24WxX0GUkTE5RGxMCIWdnTsc/HczMwO0HjVFM4E7o2IwamAnxlsFkr3a1P5avac2ncOu6f2NTOzEhuvpPAGdjcdQbaW7vnp8flks2wOlr819UI6Cdg82MxkZmalV/KkkBYceSV7Tp37KeCVkpamfYMLn9xANp3vMrJFNv6uVHHd/mgX/3nL0lKd3sysKpV88FpEdLPXKlQRsZ6sN9LexwbZvPQld8/y9Vx+x3L+52lH0FDv2T7MzKCG5z7qzLXRNxCs3jjcOuhmZrWpZpPC/I5s2dcV67aXORIzs8pRs0mhM9cOwHInBTOzITWbFKa3NjKluYEV67aVOxQzs4pRs0lBEp0d7W4+MjPLU7NJAWB+ro0VXU4KZmaDajopdObaWLN5Jzt6+8sdiplZRaj5pACwcr1rC2Zm4KQAwEpfVzAzA5wUAHdLNTMbVNNJoW1SAwdNmeQeSGZmSU0nBYB5M9ucFMzMkppPCvM7nBTMzAbVfFLozLWxYXsvm7p7yx2KmVnZOSmkOZBcWzAzc1LwWAUzszw1nxTmzmilTni6CzMznBRoaqjjsBmtHqtgZoaTApA1IfmagpmZkwKwe6xCtkS0mVntKnlSkDRN0jWSHpH0sKSTJc2QdLOkpel+ejpWki6VtEzSA5KOK3V8kI1V6O7tZ+3WnvF4OTOzijUeNYUvADdFxHOBo4GHgUuAWyJiAXBL2gY4E1iQbhcCl41DfLvnQPLFZjOrcSVNCpKmAKcCVwBERG9EbALOBhalwxYB56THZwNXReZuYJqkQ0oZI+xOCr6uYGa1rtQ1hflAF/BNSb+X9HVJbcBBEfEUQLqflY6fDazKe/7qVFZSh05toamhzmMVzKzmlTopNADHAZdFxLHAdnY3FQ1Hw5Ttc/VX0oWSFkta3NXV9ayDrKsTnTPb3HxkZjWv1ElhNbA6Iu5J29eQJYlnBpuF0v3avOMPy3v+HGDN3ieNiMsjYmFELOzo6BiTQLNuqdvG5FxmZtWqpEkhIp4GVkk6KhWdAfwRuB44P5WdD1yXHl8PvDX1QjoJ2DzYzFRq83JtPLGhm77+gfF4OTOzitQwDq/x98DVkpqA5cDbyZLRDyRdADwBnJuOvQE4C1gGdKdjx8X8XBu7+oMnN+3g8Jlt4/WyZmYVpeRJISLuAxYOs+uMYY4N4KJSxzSczo7dS3M6KZhZrfKI5mSoW6ovNptZDXNSSGa2NTG5ucHdUs2spjkpJJKY74nxzKzGOSnk6cx5rIKZ1baCk4KkiyVNSd1Fr5B0r6Q/L2Vw460z186azTvYuau/3KGYmZVFMTWFd0TEFuDPgQ6y7qKfKklUZTIv10oEPL6+u9yhmJmVRTFJYXAKirOAb0bE/Qw/LUXVmp9rB/DIZjOrWcUkhSWSfkGWFP5L0mRgQg3/nZdrBfDSnGZWs4oZvHYBcAywPCK6Jc1kHEccj4fJzY10TJ7ksQpmVrOKqSkE8HzgvWm7DWge84jKrDPX5rEKZlazikkKXwZOBt6QtrcCXxrziMrMYxXMrJYVkxROjIiLgJ0AEbERaCpJVGXUmWtj3bZeNu/YVe5QzMzGXTFJYZeketKiN5I6mGAXmmH3HEgrXVswsxpUTFK4FLgWmCXpk8CdwL+WJKoy8nrNZlbLCu59FBFXS1pCNuW1gHMi4uGSRVYmc2e2IrlbqpnVpoKTQloJ7Q8R8aW0PVnSiXlLbU4IkxrqmTO9xTUFM6tJxTQfXQbkD/XdnsomnM5cu0c1m1lNKmqai7QyGgARMcD4LOc57ubn2li5rpu8t2tmVhOKSQrLJb1XUmO6XUy25vKE05lrY1tPH13besodipnZuComKbwbeAnwJLAaOBG4sBRBlZuX5jSzWlVM76O1wOtLGEvFyO+WeuL8mWWOxsxs/BTT+6gDeBcwL/95EfGOUZ63kmxKjH6gLyIWSpoBfD+dayXwtxGxUZKAL5DNxNoNvC0i7i387YyNQ6e10FRf5x5IZlZzimk+ug6YCvwS+HnerRCnR8QxEbEwbV8C3BIRC4Bb0jbAmcCCdLuQMvVuqq8Th89s9VgFM6s5xfQeao2ID43R654NnJYeLwJuAz6Uyq9KvZzuljRN0iER8dQYvW7BOnNtTgpmVnOKqSn8TNJZB/AaAfxC0hJJgxemDxr8ok/3s1L5bGBV3nNXp7Jx19nRxhPru+kfcLdUM6sdxdQULgY+IqkH2EU21UVExJRRnndKRKyRNAu4WdIjIxw73PKe+3wrp+RyIcDcuXMLCr5Y83Nt9PYPsGbTDg6b0VqS1zAzqzQF1xQiYnJE1EVES0RMSdujJQQiYk26X0s2od4JwDOSDgFI92vT4auBw/KePgdYM8w5L4+IhRGxsKOjo9C3UJTOtF6zm5DMrJYU03yEpOmSTpB06uBtlOPb0lrOSGoD/hx4CLgeOD8ddj7ZRWxS+VuVOQnYXI7rCZA/VsHTXZhZ7SimS+o7yZqQ5gD3AScBdwEvH+FpBwHXZj1NaQC+ExE3Sfod8ANJFwBPAOem428g6466jKxLatnWgM61N9E+qcHdUs2sphR7TeF44O6IOF3Sc4FPjPSEiFgOHD1M+XqyKbj3Lg/goiJiKhlJ7oFkZjWnmOajnRGxE0DSpIh4BDiqNGFVhk6v12xmNaaYpLBa0jTgJ2S9iK5jmIvAE0lnro0nN+1g567+codiZjYuipn76K/Sw49LupVsdPONJYmqQszvaCMCVm3oZsFBk8sdjplZyRVcU5D0rcHHEXF7RFwPfKMkUVWIwR5Ivq5gZrWimOajF+RvSKoHXjy24VSWeXmzpZqZ1YJRk4KkD0vaCrxI0pZ020o24Oy6UZ5e1aY0N5Jrn+R1FcysZoyaFCLi3yJiMvCZNJJ5cDTzzIj48DjEWFaduVbXFMysZhQ7IV4bgKQ3S/qspMNLFFfF8FgFM6slxSSFy4BuSUcD/wg8DlxVkqgqSGeunXXbeti6c1e5QzEzK7likkJfGnF8NvCFiPgCMOH7aQ72QFq5rrvMkZiZlV4xSWGrpA8DbwZ+nnofNZYmrMoxv2OwW6onxjOzia+YpHAe0ANcEBFPky1+85mSRFVB5s5oRXK3VDOrDcWMaH4a+Gze9hPUwDWF5sZ6Zk9rcVIws5owalKQdGdEvDSNTchfBa3QldeqnifGM7NaUcg4hZem+8l54xQKXnltIujMtbGiazvZdXYzs4mrkJrCjJH2R8SGsQunMnXm2tja08e6bb10TJ5U7nDMzEqmkGsKS8iajQTMBTamx9PIVk3rLFl0FaIzbw4kJwUzm8gKaT7qjIj5wH8Br4mIXETMBF4N/LjUAVaC+bl2AFb6uoKZTXDFdEk9PiJuGNyIiBuBl419SJVn9vQWGuvl6S7MbMIrZo3mdZI+BnybrDnpzcD6kkRVYerrxOEz21jhAWxmNsEVU1N4A9ABXJtuHamsJrhbqpnVgoKTQkRsiIiLI+LYiDguIt6X3/NI0n/u77mS6iX9XtLP0nanpHskLZX0fUlNqXxS2l6W9s878Lc2tjpzbaxc303/gLulmtnEVUxNYTSnjLDvYuDhvO1PA5+LiAVkvZkuSOUXABsj4kjgc+m4itCZa6O3b4A1m3aUOxQzs5IZy6QwLElzgL8Evp62BbwcuCYdsgg4Jz0+O22T9p+Rji+7Ti/NaWY1oORJAfg82foLA2l7JrApIvrS9mqyyfVI96sA0v7N6fg9SLpQ0mJJi7u6ukoZ+5D5g1Nor3dSMLOJayyTwj6/6CW9GlgbEUtGOo7dcyqNtG93QcTlEbEwIhZ2dHQcULDF6pg8ibamepZ7vWYzm8CK6ZI6mi8MU3YK8FpJZwHNwBSymsM0SQ2pNjAHWJOOXw0cBqyW1ABMBSpiGg1JdHa4B5KZTWyFzH30U4b5tT4oIl6b7q8cZt+HgQ+n85wG/ENEvEnSD4HXAd8DzgeuS0+5Pm3flfb/KipoFrrOXDv3r9pU7jDMzEqmkOaj/wf8B7AC2AF8Ld22AQ8d4Ot+CPhfkpaRXTO4IpVfAcxM5f8LuOQAz18Snbk2Vm/spqevv9yhmJmVxKg1hYi4HUDSP0fEqXm7firpjkJfKCJuA25Lj5cDJwxzzE7g3ELPOd46c60MBKza0M2Rsyb88tRmVoOKudDcIWn+4IakTrJRzTWjM02M54vNZjZRFXOh+f3AbZKWp+15wP8Y84gqWOdMj1Uws4mtmDWab5K0AHhuKnokInpKE1ZlmtrayMy2Jo9VMLMJq+DmI0mtwAeB90TE/cDcNA6hpnTm2tx8ZGYTVjHXFL4J9AInp+3VwL+MeUQVzrOlmtlEVkxSOCIi/h3YBRAROxh+BPKE1tnRxtqtPWzr6Rv9YDOzKlNMUuiV1EIayCbpCKCmrinA7ovNXprTzCaiYpLC/wFuAg6TdDVwC9lEdzWlsyNLCl6a08wmooJ6H6Xpqx8B/ho4iazZ6OKIWFfC2CrSvMFuqb7YbGYTUEFJISJC0k8i4sXAz0scU0Vrbqxn9rQWr9dsZhNSMc1Hd0s6vmSRVJHOXBsr1neXOwwzszFXTFI4HbhL0mOSHpD0oKQHShVYJevMtbGiaxsVNIGrmdmYKGaaizNLFkWV6cy1sWVnHxu29zKzfVK5wzEzGzMF1xQi4vGIeJxs+uzIu9WcwR5IHsRmZhNNMdNcvFbSUrJ1FW4HVgI3liiuijY4VsHdUs1soinmmsI/k3VHfTQiOoEzgN+UJKoKN2d6Cw11ck3BzCacYpLCrohYD9RJqouIW4FjShRXRWuor2PuzFaPVTCzCaeYC82bJLUDdwBXS1oL1OwEQPNzbZ5C28wmnGJqCmeTXWR+P9l0F48BrylFUNVgcLbUgYGavNZuZhNUMYvs5P8sXlSCWKpKZ66dnr4Bntqyk9nTWsodjpnZmCim99FWSVvSbaekfklbShlcJevMeQ4kM5t4ihmnMDkipqRbM/A3wBdHeo6kZkm/lXS/pD9I+kQq75R0j6Slkr4vqSmVT0rby9L+eQf+1kpr/tBYBc+BZGYTRzHXFPYQET8BXj7KYT3AyyPiaLKeSq+SdBLwaeBzEbEA2AhckI6/ANgYEUcCn0vHVaRZkyfR2lTvsQpmNqEUfE1B0l/nbdYBCxllRHNkkwMN/pRuTLcgSyZvTOWLgI8Dl5FdzP54Kr8G+KIkRQVOMiSJeTO9NKeZTSzFdEnN72nURzai+ezRniSpHlgCHAl8iazX0qaIGOzOuhqYnR7PBlYBRESfpM3ATGDdXue8ELgQYO7cuUW8hbHV2dHGQ09uLtvrm5mNtWJ6H739QF4gIvqBYyRNA64FnjfcYel+uDWf96klRMTlwOUACxcuLFstYn6ujZseeprevgGaGg64Jc7MrGIU03x06Uj7I+K9o+zfJOk2sqkypklqSLWFOcCadNhq4DBgtaQGYCqwodAYx1tnro3+gWDVxm6O6GgvdzhmZs9aMT9vm4HjgKXpdgzQT9Y0tGS4J0jqSDUEJLUArwAeBm4FXpcOOx+4Lj2+Pm2T9v+qEq8nDHK3VDObaIq5prAAOD0idgFI+grwi4h4/wjPOQRYlK4r1AE/iIifSfoj8D1J/wL8HrgiHX8F8C1Jy8hqCK8v7u2Mr6Gk4IvNZjZBFJMUDgUms7s5pz2V7VdEPAAcO0z5cuCEYcp3AucWEVNZTWttYnpro7ulmtmEUUxS+BTwe0m3pu2Xsbv7aM3K5kDyADYzmxiK6X30TUk3AieS9Qi6JCKeLllkVaIz186dy7rKHYaZ2ZgY9UKzpMMlTQVISWAL2QI7bxycnqKWze9o45ktPWzvqdlZxM1sAimk99EPgDYASccAPwSeAI4Gvly60KrD4MVmr61gZhNBIc1HLRExOI7gzcA3IuI/JNUB95UutOqQ3wPpBYdOLXM0ZmbPTiE1hfxRxi8HbgGIiIGSRFRl5s30WAUzmzgKqSn8StIPgKeA6cCvACQdAvSWMLaq0NJUz6FTmz1WwcwmhEKSwvuA88gGor10cPAacDDw0VIFVk3m5do8VsHMJoRRk0KaZuJ7w5T/Pn9b0l0RcfIYxlY1OnNt/PT+NUQE0nBz+pmZVYexnNqzeQzPVVU6c21s2dnHxu5dox9sZlbBxjIpVOzEdaW2e2lONyGZWXXzIgBjoDOXTZvtpGBm1a6QEc2TCjxXzTamz5neQkOdPAeSmVW9QmoKdwFI+tYox73l2YdTnRrr65g7o9U1BTOreoV0SW2SdD7wEkl/vffOiPhxun9orIOrJp25NpZ7AJuZVblCksK7gTcB04DX7LUvgB+PdVDVaF6ujd88to6BgaCurmZb0sysyhUyTuFO4E5JiyPiitGOr1WduTZ27hrg6S07OXRaS7nDMTM7IMUssvMtSe8FTk3btwNfyRvhXNPm502M56RgZtWqmC6pXwZenO6/DBwHXFaKoKpRp8cqmNkEUExN4fiIODpv+1eS7h/rgKrVQZObaWmsd1Iws6pWTE2hX9IRgxuS5gP9Yx9SdaqrE/NybU4KZlbVikkKHwRulXSbpNvJptD+wEhPkHSYpFslPSzpD5IuTuUzJN0saWm6n57KJelSScskPSDpuAN9Y+Uw30nBzKpcwUkhIm4BFgDvTbejIuLWwf2SXjnM0/qAD0TE84CTgIskPR+4BLglIhaQLdpzSTr+zPQaC4ALqbJrFvNyrTyxoZtd/V5/yMyqU1FzH0VET0Q8EBH3R0TPXrs/PczxT0XEvenxVuBhYDZwNrAoHbYIOCc9Phu4KjJ3A9PSYj5VoTPXTv9AsGpDd7lDMTM7IGM5Id6II7YkzQOOBe4BDoqIpyBLHMCsdNhsYFXe01ansr3PdaGkxZIWd3V1PfvIx0j+es1mZtVoXKbOltQO/Ah4X0RsGeEcwyWWfc4bEZdHxMKIWNjR0VF8pCUy30nBzKpcyafOltRIlhCuHpwnCXhmsFko3a9N5auBw/KePgdYU+oYx8r0tiamtTY6KZhZ1RrLpLBy7wJla1NeATwcEZ/N23U9cH56fD5wXV75W1MvpJOAzYPNTNWi0z2QzKyKFTx4TVI98JfAvPznDX7ZR8Q+M6gCp5BNqf2gpPtS2UeATwE/kHQB8ARwbtp3A3AWsAzoBt5exHupCJ25Nu56bH25wzAzOyDFjGj+KbATeBAoqM9lmkxvfxegzxjm+AAuKiKmijM/18aP732S7t4+WpuK+XjNzMqvmG+tORHxopJFMkHMSxebV67r5vmHTilzNGZmxSnmmsKNkv68ZJFMEO6WambVrJiawt3AtZLqgF1kzUIREf45nGfezMGk4PWazaz6FJMU/gM4GXgwtf3bMNomNXDwlGZWrPOoZjOrPsU0Hy0FHnJCGF3WLdU1BTOrPsXUFJ4CbpN0IzA079Fe4w+MbMGdGx+squEVZmZAcUlhRbo1pZvtx/xcGxu7d7Fxey/T2/xRmVn1KDgpRMQnShnIRDLUA2n9dicFM6sqxYxovpXhJ6d7+ZhGNAE856DJAFx++3IufcOxNDWUfIopM7MxUUzz0T/kPW4G/oZsER3by2EzWvnoWc/jkzc8zLuuWsxX3vxiWprqyx2Wmdmoimk+WrJX0W/Sspw2jHedOp/25gY+cu2DvPUb93DF245nSnNjucMyMxtRwe0aaV3lwVtO0quAg0sYW9V7wwlzufT1x/L7Jzbxxq/dzfptey9WZ2ZWWYppPlrC7msKfWRTZV8w1gFNNK85+lDaJzXw7m8v4W+/ehfffueJHDK1pdxhmZkNa9SagqTjJR0cEZ0RMR/4BPBIuv2x1AFOBKc/dxaL3nECz2zp4XWX3cVKz4tkZhWqkOajrwK9AJJOBf4NWARsBi4vXWgTy0nzZ/Kdd51Id28f5371Lh55eqRVSc3MyqOQpFAfERvS4/OAyyPiRxHxT8CRpQtt4nnRnGn84H+cTJ3gvK/ezX2rNpU7JDOzPRSUFCQNXns4A/hV3j6vIlOkBQdN5pp3v4SpLY286Wt389+PrSt3SGZmQwpJCt8Fbpd0HbAD+DWApCPJmpCsSIfNaOWH7z6Z2dNbeNs3f8fNf3ym3CGZmQEFJIWI+CTwAeBK4KV5s6TWAX9futAmtoOmNPP9C0/muQdP5t3fXsJ19z1Z7pDMzAobpxARd0fEtRGxPa/s0Yi4t3ShTXzT25q4+p0nsvDw6bzv+/fxrbsfL3dIZlbjPClPmU1ubmTRO07g5UfN4p9+8hBfvm1ZuUMysxpW0qQg6RuS1kp6KK9shqSbJS1N99NTuSRdKmmZpAckHVfK2CpJc2M9X3nLi3nN0Yfy7zf9iU/f9Ahey8jMyqHUNYUrgVftVXYJcEtELABuSdsAZwIL0u1C4LISx1ZRGtttydsAAAySSURBVOvr+Px5x/DGE+dy2W2P8U/XPcTAgBODmY2vknYpjYg7JM3bq/hs4LT0eBFwG/ChVH5VupB9t6Rpkg6JiJpZwqy+TnzynBcyubmBr96+nG07+/jMuUfTWO9WPjMbH+UYZ3DQ4Bd9RDwlaVYqnw2syjtudSrbJylIupCsNsHcuXNLG+04k8Qlr3ouU5ob+cx//YltPf188Y3H0tzoqbfNrPQq6Seohikbtv0kIi6PiIURsbCjo6PEYY0/SVx0+pH889kv4JcPP8M7rvwd23q8dIWZlV45ksIzkg4BSPdrU/lq4LC84+YAa8Y5torylpPn8bnzjuaeFRt489fvYVN3b7lDMrMJrhxJ4Xrg/PT4fOC6vPK3pl5IJwGba+l6wv781bFz+PKbjuOPa7Zw3lfvZu2WneUOycwmsFJ3Sf0ucBdwlKTVki4APgW8UtJS4JVpG+AGYDmwDPga8HeljK2a/MULDuabbz+eVRu7Oferd7FqQ3e5QzKzCUrV3h9+4cKFsXjx4nKHMS6WPL6Rt3/zt7Q2NfD18xfywtlTyx2SmVUpSUsiYuE+5U4K1eXhp7bwlit+y7ptPcyd0cqfLchx6nM6eMkRM5nsNaDNrEBOChPI2q07ufHBp/n10i7++7H1dPf201Anjps7fShJvHD2VOrrhuvQZWbmpDBh9fYNsOTxjfx6aRd3LO3ioSezFd2mtzZyypFZgjh1QQcHT20uc6RmVkmcFGrE+m093LlsHbc/2sWvl66ja2sPAM85qJ1TF3Rw6nM6OKFzhgfDmdU4J4UaFBE88vRW7kgJ4rcrNtDbP8CkhjpO6JzBy56TJYkFs9qR3NRkVkucFIwdvf3cvWI9v350HXcs7WLZ2m0AHDyleehaxEuPzDG9ranMkZpZqe0vKXiN5RrS0lTP6UfN4vSjsumm1mzakV2LeHQdv/jjM/xwyWokeMGhUziyo53DZ7Zx+MzWdGtjZluTaxRmE5xrCgZA/0DwwOpN3PHoOn67cj0r13WzZvMO8v882prqmTuzjXkzW5k7s5V5M9s4fEb2+JCpLe7tZFZFXFOwEdXXiWPnTufYudPJlrSAnr5+Vm/cwRPru1m5fjuPr+/miQ3d/OmZrdzy8Fp6+weGnt9UX8ecGS0cPqN1nxrGnOktTGrwhW2zauCkYPs1qaGeIzraOaKjfZ99/QPB01t28vi67Ty+IUsaT6zv5vH13fx2xQa29/YPHSvBoVNbhhLFwVNayE1uoqN9ErnJk7L79km0NDlxmJWbk4IdkPo6MXtaC7OntfCSvfZFBOu39/J4ql1ktyx5/OIPz7B++/CzvbZPaiDX3kQuJYkscTSTm7y7bNZkJxCzUnJSsDEnaehL/MWHz9hnf2/fAOu397Buay9d23am+x7Wbeth3bZeurbuZFnXNu5e0cOm7l3DvkZbUz25lCA6UgLJtU9iZvskpjQ3MLWlkSktjUxpbmRKSwNTmhs9NsOsAE4KNu6aGuo4ZGoLh0xtAUae1C8/gazb1jOUPLq2Zglk3dYeHuvaxj0reti4nwSS/7pTWxqZ0tyQlzAa95tE8vdNbm6kqaGS1qQyKw0nBatoeyaQke3qH2Dj9l627NzF5h19bNm5iy07drFlZ192v2NXKsv2berOmrgG9/cNjNwTr6WxnsnNDbQ3NzC5uZHJkxqy7UnZdntzw+6ydEz7pAam5G23NtZT515aVsGcFGzCaKyvY9aUZmZNKX6ep4hgx67+oYSxee8ksiMr29bTx9adfWzt6WPrzl08s2XnUFkhS6ZK2bWTyfmJJCWWtqYGGhtEY30dTfV1NNbX0VCfvy0aG+r22D9Ytsd2fR1N6biGOg09ntSQlTfUyeNNbL+cFMzIroO0NjXQ2tRwwJMHDgwE23r72LZzMEnsyhJIShhbd+5i284+tqTtbTv72Nqzi43be3lifTfdvf30DQzQ2zfArv5gV//AqLWXA1GnrAbWVF/HpMb6dL97e9Ie2+m+oZ6mht2JZe/txnpRX1dHfR3ZvUR9XXZrqBN1g/cSDfXpvm73MUO3/TwvP8k5oZWWk4LZGKmrU3YtYgzXtRgYCHYNpCTRN8Cu/gF6+3cnjd5UNrTdP5COy9vOO65nV1bW05eV9fT109OXvz1Ab18/23r68rZ3HztYVopkVaimhryaU6oVDdWUGjT0eM/y7PhJDYM1qt3HNNaJhnS+hj0e766pNdRpqObWUJf271XemI7f43FdHVLWW69Ook5UfFJzUjCrYHV1YlJdPZMagEnljma3/oHYI1nsGggGBoK+gaB/71sE/QMD9A9A38AAA4P3EfT1R3a/3+cFu/qDvsHk1h95iTAlur59k2Zv3wDbe/rYlHf8ngkyho4rhyxJZAmiTlCnrJYkZf/mWQLZva9uj/JUVic+8doXcMqRuTGNzUnBzIpWXydamurTeJHqXfEvUuLpG0jNdf1ZzayvP/Z4PNiU15dqZX155YPbQ8krHdfXn513IIKIYCBgILLkOfR4mLKILCEORBbfwABpO4h0TP9A9rh90th/hTspmFnNUrrG0VCPx7Ek7nhtZmZDKi4pSHqVpD9JWibpknLHY2ZWSyoqKUiqB74EnAk8H3iDpOeXNyozs9pRUUkBOAFYFhHLI6IX+B5wdpljMjOrGZWWFGYDq/K2V6eyPUi6UNJiSYu7urrGLTgzs4mu0pLCcKM69hklExGXR8TCiFjY0dExDmGZmdWGSksKq4HD8rbnAGvKFIuZWc2ptKTwO2CBpE5JTcDrgevLHJOZWc1QRPnmMBmOpLOAzwP1wDci4pOjHN8FPD4esR2AHLCu3EEcgGqNGxx7uTj28ng2sR8eEfu0v1dcUphIJC2OiIXljqNY1Ro3OPZycezlUYrYK635yMzMyshJwczMhjgplNbl5Q7gAFVr3ODYy8Wxl8eYx+5rCmZmNsQ1BTMzG+KkYGZmQ5wUxpikwyTdKulhSX+QdHG5YyqWpHpJv5f0s3LHUgxJ0yRdI+mR9PmfXO6YCiXp/env5SFJ35XUXO6Y9kfSNyStlfRQXtkMSTdLWprup5czxuHsJ+7PpL+XByRdK2laOWPcn+Fiz9v3D5JC0pisy+mkMPb6gA9ExPOAk4CLqnD674uBh8sdxAH4AnBTRDwXOJoqeQ+SZgPvBRZGxAvJBm6+vrxRjehK4FV7lV0C3BIRC4Bb0naluZJ9474ZeGFEvAh4FPjweAdVoCvZN3YkHQa8EnhirF7ISWGMRcRTEXFveryV7Itpn5leK5WkOcBfAl8vdyzFkDQFOBW4AiAieiNiU3mjKkoD0CKpAWilguf8iog7gA17FZ8NLEqPFwHnjGtQBRgu7oj4RUT0pc27yeZbqzj7+cwBPgf8I8NMHHqgnBRKSNI84FjgnvJGUpTPk/2RDZQ7kCLNB7qAb6amr69Lait3UIWIiCeB/0f2a+8pYHNE/KK8URXtoIh4CrIfRsCsMsdzIN4B3FjuIAol6bXAkxFx/1ie10mhRCS1Az8C3hcRW8odTyEkvRpYGxFLyh3LAWgAjgMui4hjge1UZhPGPlL7+9lAJ3Ao0CbpzeWNqrZI+ihZ0+/V5Y6lEJJagY8C/3usz+2kUAKSGskSwtUR8eNyx1OEU4DXSlpJturdyyV9u7whFWw1sDoiBmtl15AliWrwCmBFRHRFxC7gx8BLyhxTsZ6RdAhAul9b5ngKJul84NXAm6J6Bm4dQfYj4v70/3UOcK+kg5/tiZ0UxpgkkbVrPxwRny13PMWIiA9HxJyImEd2ofNXEVEVv1gj4mlglaSjUtEZwB/LGFIxngBOktSa/n7OoEoukue5Hjg/PT4fuK6MsRRM0quADwGvjYjucsdTqIh4MCJmRcS89P91NXBc+n/wrDgpjL1TgLeQ/cq+L93OKndQNeLvgaslPQAcA/xrmeMpSKrdXAPcCzxI9v+yYqdekPRd4C7gKEmrJV0AfAp4paSlZL1hPlXOGIezn7i/CEwGbk7/V79S1iD3Yz+xl+a1qqe2ZGZmpeaagpmZDXFSMDOzIU4KZmY2xEnBzMyGOCmYmdkQJwWzMSZp3nCzWZpVAycFMzMb4qRgVkKS5qcJ+o4vdyxmhXBSMCuRNOXGj4C3R8Tvyh2PWSEayh2A2QTVQTb/z99ExB/KHYxZoVxTMCuNzcAqsrmwzKqGawpmpdFLtvrYf0naFhHfKXdAZoVwUjArkYjYnhYuulnS9oioiumkrbZ5llQzMxviawpmZjbEScHMzIY4KZiZ2RAnBTMzG+KkYGZmQ5wUzMxsiJOCmZkN+f/gCXgIqgS3ggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "SSD = []\n",
    "lab = []\n",
    "for k in range(1,15):\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(train)\n",
    "    SSD.append(km.inertia_)\n",
    "    lab.append(km.labels_)\n",
    "K = range(1,15)\n",
    "%matplotlib inline\n",
    "plt.plot(K,SSD)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_Squared_distances')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "[681.3706, 152.34795176035792, 78.85144142614601, 57.25600931571815, 46.44618205128205, 39.35425513506102, 34.40900974025974, 29.98894395078606, 28.168759740259745, 25.88463975060028, 24.814359986504726, 22.898075383594733, 21.359896351455564, 20.677755131786597]\n"
     ]
    }
   ],
   "source": [
    "j = 1\n",
    "for l in range(1,14):\n",
    "    if(SSD[j]-SSD[j-1]<SSD[l]-SSD[l-1]):\n",
    "        j=l\n",
    "print(j)\n",
    "print(SSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 0 0 2 0 0 0 0\n",
      " 0 0 2 2 0 0 0 0 2 0 2 0 2 0 0 2 2 0 0 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 2 0\n",
      " 0 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 3 1 3 1 3 1 3 3 3 3 1 3 1 1 3 1 3 1 3 1 1\n",
      " 1 1 1 1 1 3 3 3 3 1 3 1 1 1 3 3 3 1 3 3 3 3 3 1 3 3 2 1 2 2 2 2 3 2 2 2 1\n",
      " 1 2 1 1 2 2 2 2 1 2 1 2 1 2 2 1 1 2 2 2 2 2 1 1 2 2 2 1 2 2 2 1 2 2 2 1 1\n",
      " 2 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 4 2 2 2 4 2 4 4 2 4 2 4 2 2 4 2 4 2 4 2 2\n",
      " 2 2 2 2 2 4 4 4 4 2 4 2 2 2 4 4 4 2 4 4 4 4 4 2 4 4 0 2 3 0 0 3 4 3 0 3 0\n",
      " 0 0 2 0 0 0 3 3 2 0 2 3 2 0 3 2 2 0 3 3 3 0 2 2 3 0 0 2 0 0 0 2 0 0 0 2 0\n",
      " 0 2]\n",
      "[1 1 1 1 1 5 1 1 1 1 5 1 1 1 5 5 5 1 5 5 5 5 1 1 1 1 1 5 1 1 1 5 5 5 1 1 5\n",
      " 1 1 1 1 1 1 1 5 1 5 1 5 1 3 3 3 2 3 3 3 2 3 2 2 3 2 3 2 3 3 2 3 2 3 2 3 3\n",
      " 3 3 3 3 3 2 2 2 2 3 2 3 3 3 2 2 2 3 2 2 2 2 2 3 2 2 0 3 4 0 0 4 2 4 0 4 0\n",
      " 0 0 3 0 0 0 4 4 3 0 3 4 3 0 4 3 3 0 4 4 4 0 3 3 4 0 0 3 0 0 0 3 0 0 0 3 0\n",
      " 0 3]\n",
      "[0 3 3 3 0 0 3 0 3 3 0 3 3 3 0 0 0 0 0 0 0 0 3 0 3 3 0 0 0 3 3 0 0 0 3 3 0\n",
      " 0 3 0 0 3 3 0 0 3 0 3 0 3 2 2 2 5 2 2 2 5 2 5 5 2 5 2 5 2 2 5 2 5 4 2 4 2\n",
      " 2 2 2 2 2 5 5 5 5 4 5 2 2 2 5 5 5 2 5 5 5 5 5 2 5 5 6 4 1 6 6 1 5 1 6 1 6\n",
      " 4 6 4 4 6 6 1 1 4 6 4 1 4 6 1 4 4 6 1 1 1 6 4 4 1 6 6 4 6 6 6 4 6 6 6 4 6\n",
      " 6 4]\n",
      "[1 5 5 5 1 1 5 1 5 5 1 5 5 5 1 1 1 1 1 1 1 1 5 1 5 5 1 1 1 5 5 1 1 1 5 5 1\n",
      " 1 5 1 1 5 5 1 1 5 1 5 1 5 7 7 7 6 7 6 7 0 7 6 0 6 6 7 6 7 6 6 4 6 4 6 4 7\n",
      " 7 7 7 7 7 0 0 0 6 4 6 7 7 7 6 6 6 7 6 0 6 6 6 7 0 6 2 4 3 2 2 3 6 3 2 3 2\n",
      " 4 2 4 4 2 2 3 3 4 2 4 3 4 2 3 4 4 2 3 3 3 2 4 4 3 2 2 4 2 2 2 4 2 2 2 4 2\n",
      " 2 4]\n",
      "[0 5 5 5 0 0 5 0 5 5 0 5 5 5 0 0 0 0 0 0 0 0 5 0 5 5 0 0 0 5 5 0 0 0 5 5 0\n",
      " 0 5 0 0 5 5 0 0 5 0 5 0 5 6 6 6 7 6 3 6 8 6 3 8 3 7 6 7 6 3 7 6 7 1 7 1 6\n",
      " 6 6 6 6 6 7 7 7 7 1 3 6 6 6 3 7 3 6 7 8 3 3 3 6 8 3 2 1 4 2 2 4 3 4 2 4 2\n",
      " 1 2 1 1 2 2 4 4 1 2 1 4 1 2 4 1 1 2 4 4 4 2 1 1 4 2 2 1 2 2 2 1 2 2 2 1 2\n",
      " 2 1]\n",
      "[7 1 1 1 7 5 1 7 1 1 7 7 1 1 5 5 5 7 5 7 7 7 1 7 7 1 7 7 7 1 1 7 5 5 1 1 7\n",
      " 7 1 7 7 1 1 7 7 1 7 1 7 7 0 0 0 8 0 2 0 4 0 8 4 2 8 2 8 0 2 8 2 8 9 2 9 2\n",
      " 2 0 0 0 2 8 8 8 8 9 8 2 0 2 8 8 8 2 8 4 8 8 8 2 4 8 6 9 3 6 6 3 8 3 6 3 6\n",
      " 9 6 9 9 6 6 3 3 9 6 9 3 9 6 3 9 9 6 3 3 3 6 9 9 3 6 6 9 6 6 6 9 6 6 6 9 6\n",
      " 6 9]\n",
      "[10  0  0  0 10  4  0 10  0  0  4 10  0  0  4  4  4 10  4  4 10 10  0 10\n",
      " 10  0 10 10 10  0  0 10  4  4  0 10  4 10  0 10 10  0  0 10  4  0  4  0\n",
      "  4 10  5  5  5  3  5  8  5  9  5  8  9  8  3  5  3  5  8  3  1  3  7  3\n",
      "  1  5  5  5  5  5  5  3  3  3  3  1  8  5  5  5  8  3  8  5  3  9  8  8\n",
      "  8  5  9  8  2  7  2  2  2  6  8  6  2  6  2  1  2  7  7  2  2  6  6  1\n",
      "  2  7  6  1  2  6  1  7  2  2  6  6  2  1  1  6  2  2  7  2  2  2  7  2\n",
      "  2  2  1  2  2  7]\n",
      "[ 7  1  1  1  7  6  1  7  1  1  7  7  1  1  6  6  6  7  6  7  7  7  1  7\n",
      "  7  1  7  7  7  1  1  7  6  6  1  1  7  7  1  7  7  1  1  7  7  1  7  1\n",
      "  7  7  5  5  5  2  5 11  5  8  5  2  8 11  2 11  2  5 11  2  4  2 11  2\n",
      "  4 11  5  5  5  5 11  2  2  2  2  4 11 11  5 11  2  2  2 11  2  8  2  2\n",
      "  2 11  8  2 10  4  9  0 10  3  2  9  0  9  0  0  0  4  4 10  0  3  3  4\n",
      " 10  4  3  4 10  9  4  4  0  9  9  3  0  4  4  9 10  0  4  0 10  0  4 10\n",
      " 10  0  4  0 10  4]\n",
      "[ 1  7  7  7  1 12  7  1  7  7 12  1  7  7 12 12 12  1 12 12  1  1  7  1\n",
      "  1  7  1  1  1  7  7  1 12 12  7  1 12  1  7  1  1  7  7  1 12  7 12  7\n",
      " 12  1 10  6 10  9  6  2  6  5 10  9  5  2  9  6  9 10  2  9  6  9  4  6\n",
      "  4  6  6 10 10 10  6  9  9  9  9  4  2  6 10  6  2  9  2  6  9  5  2  2\n",
      "  2  6  5  2  0  4  3 11  0  8  2  3 11  8  0 11  0  4  4  0 11  8  8  4\n",
      "  0  4  8  4  0  3  4  4 11  3  3  8 11  4 11  8  0 11  4  0  0  0  4  0\n",
      "  0  0  4 11  0  4]\n",
      "[ 6  1  1  1  6  8  1  6  1  1  8  6  1  1  8  8  8  6  8  6  6  6  1  6\n",
      "  6  1  6  6  6  1  1  6  8  8  1  1  6  6  1  6  6  1  1  6  6  1  6  1\n",
      "  6  6  5  5  5  0  5  7  5 10  5  0 10  7  0  7  0  5  7  0  9  0  4  0\n",
      "  9  7  5  5  5  5  7  0  0  0  0  4  7  7  5  9  0  0  0  7  0 10  0  0\n",
      "  0  7 10  0 12  4 12  2 12  3 13  3 12 12  2  2 12  4  4  2  2 11  3  9\n",
      " 12  4  3  9 12 12  4  4  2 12  3 11  2  9  9  3  2  2  4 12 12  2  4 12\n",
      " 12  2  9  2  2  4]\n"
     ]
    }
   ],
   "source": [
    "for i in lab:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,15):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Species'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_3 = KMeans(n_clusters = 3)\n",
    "km_3.fit(train)\n",
    "# train['Clusters']=km_3.predict(train)\n",
    "# x = km_3.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Species'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Species'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-4437c8e0aa0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Species'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Clusters'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Species'"
     ]
    }
   ],
   "source": [
    "pd.crosstab(train['Species'],train['Clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.00600000e+00,  3.42800000e+00,  1.46200000e+00,\n",
       "         2.46000000e-01,  1.00000000e+00,  0.00000000e+00],\n",
       "       [ 5.90161290e+00,  2.74838710e+00,  4.39354839e+00,\n",
       "         1.43387097e+00, -1.22124533e-15,  1.22580645e+00],\n",
       "       [ 6.85000000e+00,  3.07368421e+00,  5.74210526e+00,\n",
       "         2.07105263e+00,  2.00000000e+00,  1.94736842e+00]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "closest, _ = pairwise_distances_argmin_min(km_3.cluster_centers_, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 78,   7, 112], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reductionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components  = 3)\n",
    "x = iris.data\n",
    "pca = pca.fit(x)\n",
    "\n",
    "x_dr = pca.transform(x)\n",
    "x_dr = pd.DataFrame(x_dr)\n",
    "x_dr.columns = ['PCA1','PCA2','PCA3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>PCA3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.684126</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>-0.027915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.714142</td>\n",
       "      <td>-0.177001</td>\n",
       "      <td>-0.210464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.888991</td>\n",
       "      <td>-0.144949</td>\n",
       "      <td>0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.745343</td>\n",
       "      <td>-0.318299</td>\n",
       "      <td>0.031559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.728717</td>\n",
       "      <td>0.326755</td>\n",
       "      <td>0.090079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.280860</td>\n",
       "      <td>0.741330</td>\n",
       "      <td>0.168678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.820538</td>\n",
       "      <td>-0.089461</td>\n",
       "      <td>0.257892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.626145</td>\n",
       "      <td>0.163385</td>\n",
       "      <td>-0.021879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.886383</td>\n",
       "      <td>-0.578312</td>\n",
       "      <td>0.020760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.672756</td>\n",
       "      <td>-0.113774</td>\n",
       "      <td>-0.197633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-2.506947</td>\n",
       "      <td>0.645069</td>\n",
       "      <td>-0.075318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-2.612755</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>0.102150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.786109</td>\n",
       "      <td>-0.235112</td>\n",
       "      <td>-0.206844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-3.223804</td>\n",
       "      <td>-0.511395</td>\n",
       "      <td>0.061300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.644750</td>\n",
       "      <td>1.178765</td>\n",
       "      <td>-0.151628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2.386039</td>\n",
       "      <td>1.338062</td>\n",
       "      <td>0.277777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.623528</td>\n",
       "      <td>0.810680</td>\n",
       "      <td>0.138183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-2.648297</td>\n",
       "      <td>0.311849</td>\n",
       "      <td>0.026668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-2.199820</td>\n",
       "      <td>0.872839</td>\n",
       "      <td>-0.120306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-2.587986</td>\n",
       "      <td>0.513560</td>\n",
       "      <td>0.213665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-2.310256</td>\n",
       "      <td>0.391346</td>\n",
       "      <td>-0.239444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-2.543705</td>\n",
       "      <td>0.432996</td>\n",
       "      <td>0.208457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-3.215939</td>\n",
       "      <td>0.133468</td>\n",
       "      <td>0.292397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-2.302733</td>\n",
       "      <td>0.098709</td>\n",
       "      <td>0.039123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-2.355754</td>\n",
       "      <td>-0.037282</td>\n",
       "      <td>0.125021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-2.506669</td>\n",
       "      <td>-0.146017</td>\n",
       "      <td>-0.253420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-2.468820</td>\n",
       "      <td>0.130951</td>\n",
       "      <td>0.094911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-2.562320</td>\n",
       "      <td>0.367719</td>\n",
       "      <td>-0.078494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-2.639535</td>\n",
       "      <td>0.312040</td>\n",
       "      <td>-0.145909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-2.631989</td>\n",
       "      <td>-0.196961</td>\n",
       "      <td>0.040771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2.427818</td>\n",
       "      <td>0.378196</td>\n",
       "      <td>0.219119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.199001</td>\n",
       "      <td>-0.606092</td>\n",
       "      <td>0.511856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3.499920</td>\n",
       "      <td>0.460674</td>\n",
       "      <td>-0.573182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.388766</td>\n",
       "      <td>-0.204399</td>\n",
       "      <td>-0.064523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2.275431</td>\n",
       "      <td>0.334991</td>\n",
       "      <td>0.286150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2.614090</td>\n",
       "      <td>0.560901</td>\n",
       "      <td>-0.205535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.258508</td>\n",
       "      <td>-0.179705</td>\n",
       "      <td>0.045848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.291132</td>\n",
       "      <td>-0.116669</td>\n",
       "      <td>0.231256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2.123609</td>\n",
       "      <td>-0.209729</td>\n",
       "      <td>0.154180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2.388003</td>\n",
       "      <td>0.464640</td>\n",
       "      <td>-0.449530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2.841673</td>\n",
       "      <td>0.375269</td>\n",
       "      <td>-0.498898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3.230674</td>\n",
       "      <td>1.374165</td>\n",
       "      <td>-0.114548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2.159438</td>\n",
       "      <td>-0.217278</td>\n",
       "      <td>0.208763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1.444161</td>\n",
       "      <td>-0.143413</td>\n",
       "      <td>-0.153234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1.781295</td>\n",
       "      <td>-0.499902</td>\n",
       "      <td>-0.172875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3.076500</td>\n",
       "      <td>0.688086</td>\n",
       "      <td>-0.335592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2.144243</td>\n",
       "      <td>0.140064</td>\n",
       "      <td>0.734879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1.905098</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>0.162180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.169326</td>\n",
       "      <td>-0.164990</td>\n",
       "      <td>0.281836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2.107611</td>\n",
       "      <td>0.372288</td>\n",
       "      <td>0.027291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2.314155</td>\n",
       "      <td>0.183651</td>\n",
       "      <td>0.322694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.922268</td>\n",
       "      <td>0.409203</td>\n",
       "      <td>0.113587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1.415236</td>\n",
       "      <td>-0.574916</td>\n",
       "      <td>0.296323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2.563013</td>\n",
       "      <td>0.277863</td>\n",
       "      <td>0.292570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2.418746</td>\n",
       "      <td>0.304798</td>\n",
       "      <td>0.504483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.944110</td>\n",
       "      <td>0.187532</td>\n",
       "      <td>0.177825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1.527167</td>\n",
       "      <td>-0.375317</td>\n",
       "      <td>-0.121898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.764346</td>\n",
       "      <td>0.078859</td>\n",
       "      <td>0.130482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.900942</td>\n",
       "      <td>0.116628</td>\n",
       "      <td>0.723252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.390189</td>\n",
       "      <td>-0.282661</td>\n",
       "      <td>0.362910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PCA1      PCA2      PCA3\n",
       "0   -2.684126  0.319397 -0.027915\n",
       "1   -2.714142 -0.177001 -0.210464\n",
       "2   -2.888991 -0.144949  0.017900\n",
       "3   -2.745343 -0.318299  0.031559\n",
       "4   -2.728717  0.326755  0.090079\n",
       "5   -2.280860  0.741330  0.168678\n",
       "6   -2.820538 -0.089461  0.257892\n",
       "7   -2.626145  0.163385 -0.021879\n",
       "8   -2.886383 -0.578312  0.020760\n",
       "9   -2.672756 -0.113774 -0.197633\n",
       "10  -2.506947  0.645069 -0.075318\n",
       "11  -2.612755  0.014730  0.102150\n",
       "12  -2.786109 -0.235112 -0.206844\n",
       "13  -3.223804 -0.511395  0.061300\n",
       "14  -2.644750  1.178765 -0.151628\n",
       "15  -2.386039  1.338062  0.277777\n",
       "16  -2.623528  0.810680  0.138183\n",
       "17  -2.648297  0.311849  0.026668\n",
       "18  -2.199820  0.872839 -0.120306\n",
       "19  -2.587986  0.513560  0.213665\n",
       "20  -2.310256  0.391346 -0.239444\n",
       "21  -2.543705  0.432996  0.208457\n",
       "22  -3.215939  0.133468  0.292397\n",
       "23  -2.302733  0.098709  0.039123\n",
       "24  -2.355754 -0.037282  0.125021\n",
       "25  -2.506669 -0.146017 -0.253420\n",
       "26  -2.468820  0.130951  0.094911\n",
       "27  -2.562320  0.367719 -0.078494\n",
       "28  -2.639535  0.312040 -0.145909\n",
       "29  -2.631989 -0.196961  0.040771\n",
       "..        ...       ...       ...\n",
       "120  2.427818  0.378196  0.219119\n",
       "121  1.199001 -0.606092  0.511856\n",
       "122  3.499920  0.460674 -0.573182\n",
       "123  1.388766 -0.204399 -0.064523\n",
       "124  2.275431  0.334991  0.286150\n",
       "125  2.614090  0.560901 -0.205535\n",
       "126  1.258508 -0.179705  0.045848\n",
       "127  1.291132 -0.116669  0.231256\n",
       "128  2.123609 -0.209729  0.154180\n",
       "129  2.388003  0.464640 -0.449530\n",
       "130  2.841673  0.375269 -0.498898\n",
       "131  3.230674  1.374165 -0.114548\n",
       "132  2.159438 -0.217278  0.208763\n",
       "133  1.444161 -0.143413 -0.153234\n",
       "134  1.781295 -0.499902 -0.172875\n",
       "135  3.076500  0.688086 -0.335592\n",
       "136  2.144243  0.140064  0.734879\n",
       "137  1.905098  0.049301  0.162180\n",
       "138  1.169326 -0.164990  0.281836\n",
       "139  2.107611  0.372288  0.027291\n",
       "140  2.314155  0.183651  0.322694\n",
       "141  1.922268  0.409203  0.113587\n",
       "142  1.415236 -0.574916  0.296323\n",
       "143  2.563013  0.277863  0.292570\n",
       "144  2.418746  0.304798  0.504483\n",
       "145  1.944110  0.187532  0.177825\n",
       "146  1.527167 -0.375317 -0.121898\n",
       "147  1.764346  0.078859  0.130482\n",
       "148  1.900942  0.116628  0.723252\n",
       "149  1.390189 -0.282661  0.362910\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_dr ['labels']= iris.target\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "x = x_dr.iloc[:,0:2]\n",
    "y = x_dr['labels'].copy()\n",
    "\n",
    "rfc.fit(x,y)\n",
    "preds_rfc = rfc.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 50,  0],\n",
       "       [ 0,  0, 50]], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_rfc = confusion_matrix(y,preds_rfc)\n",
    "cm_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_Old = iris.data\n",
    "Y_Old = iris.target\n",
    "rfc_2 = RandomForestClassifier()\n",
    "rfc_2.fit(X_Old,Y_Old)\n",
    "preds_rfc_2 = rfc_2.predict(X_Old)\n",
    "cm_rfc_2  = confusion_matrix(Y_Old,preds_rfc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 49,  1],\n",
       "       [ 0,  0, 50]], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_rfc_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Downloading https://files.pythonhosted.org/packages/00/a3/dfdbd5db6ba7f5b5a34d969c7508866c48826c61eb5e2c913d27f8784ff4/opencv_contrib_python-4.1.1.26-cp37-cp37m-win_amd64.whl (45.4MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.16.4)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.1.1.26\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-contrib-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
